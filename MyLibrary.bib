
@article{akhtar_threat_2018,
	title = {Threat of {Adversarial} {Attacks} on {Deep} {Learning} in {Computer} {Vision}: {A} {Survey}},
	volume = {6},
	issn = {2169-3536},
	shorttitle = {Threat of {Adversarial} {Attacks} on {Deep} {Learning} in {Computer} {Vision}},
	doi = {10.1109/ACCESS.2018.2807385},
	abstract = {Deep learning is at the heart of the current rise of artificial intelligence. In the field of computer vision, it has become the workhorse for applications ranging from self-driving cars to surveillance and security. Whereas, deep neural networks have demonstrated phenomenal success (often beyond human capabilities) in solving complex problems, recent studies show that they are vulnerable to adversarial attacks in the form of subtle perturbations to inputs that lead a model to predict incorrect outputs. For images, such perturbations are often too small to be perceptible, yet they completely fool the deep learning models. Adversarial attacks pose a serious threat to the success of deep learning in practice. This fact has recently led to a large influx of contributions in this direction. This paper presents the first comprehensive survey on adversarial attacks on deep learning in computer vision. We review the works that design adversarial attacks, analyze the existence of such attacks and propose defenses against them. To emphasize that adversarial attacks are possible in practical conditions, we separately review the contributions that evaluate adversarial attacks in the real-world scenarios. Finally, drawing on the reviewed literature, we provide a broader outlook of this research direction.},
	journal = {IEEE Access},
	author = {Akhtar, N. and Mian, A.},
	year = {2018},
	keywords = {adversarial attacks, adversarial learning, adversarial perturbation, artificial intelligence, black-box attack, Computational modeling, computer vision, Computer vision, Deep learning, deep learning models, deep neural networks, humanities, learning (artificial intelligence), Machine learning, neural nets, Neural networks, perturbation detection, Perturbation methods, Predictive models, self-driving cars, Task analysis, white-box attack},
	pages = {14410--14430},
	file = {IEEE Xplore Abstract Record:/Users/tiffanychien/Zotero/storage/GW453795/8294186.html:text/html;IEEE Xplore Full Text PDF:/Users/tiffanychien/Zotero/storage/XFMPXRRF/Akhtar and Mian - 2018 - Threat of Adversarial Attacks on Deep Learning in .pdf:application/pdf}
}

@article{alzantot_generating_2018,
	title = {Generating {Natural} {Language} {Adversarial} {Examples}},
	url = {http://arxiv.org/abs/1804.07998},
	abstract = {Deep neural networks (DNNs) are vulnerable to adversarial examples, perturbations to correctly classified examples which can cause the model to misclassify. In the image domain, these perturbations are often virtually indistinguishable to human perception, causing humans and state-of-the-art models to disagree. However, in the natural language domain, small perturbations are clearly perceptible, and the replacement of a single word can drastically alter the semantics of the document. Given these challenges, we use a black-box population-based optimization algorithm to generate semantically and syntactically similar adversarial examples that fool well-trained sentiment analysis and textual entailment models with success rates of 97\% and 70\%, respectively. We additionally demonstrate that 92.3\% of the successful sentiment analysis adversarial examples are classified to their original label by 20 human annotators, and that the examples are perceptibly quite similar. Finally, we discuss an attempt to use adversarial training as a defense, but fail to yield improvement, demonstrating the strength and diversity of our adversarial examples. We hope our findings encourage researchers to pursue improving the robustness of DNNs in the natural language domain.},
	urldate = {2019-06-05},
	journal = {arXiv:1804.07998 [cs]},
	author = {Alzantot, Moustafa and Sharma, Yash and Elgohary, Ahmed and Ho, Bo-Jhang and Srivastava, Mani and Chang, Kai-Wei},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.07998},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1804.07998 PDF:/Users/tiffanychien/Zotero/storage/7L9Z3UUN/Alzantot et al. - 2018 - Generating Natural Language Adversarial Examples.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/JXEQKYUY/1804.html:text/html}
}

@article{serban_adversarial_2018,
	title = {Adversarial {Examples} - {A} {Complete} {Characterisation} of the {Phenomenon}},
	url = {http://arxiv.org/abs/1810.01185},
	abstract = {We provide a complete characterisation of the phenomenon of adversarial examples - inputs intentionally crafted to fool machine learning models. We aim to cover all the important concerns in this field of study: (1) the conjectures on the existence of adversarial examples, (2) the security, safety and robustness implications, (3) the methods used to generate and (4) protect against adversarial examples and (5) the ability of adversarial examples to transfer between different machine learning models. We provide ample background information in an effort to make this document self-contained. Therefore, this document can be used as survey, tutorial or as a catalog of attacks and defences using adversarial examples.},
	urldate = {2019-06-05},
	journal = {arXiv:1810.01185 [cs]},
	author = {Serban, Alexandru Constantin and Poll, Erik and Visser, Joost},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.01185},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv\:1810.01185 PDF:/Users/tiffanychien/Zotero/storage/583D94MJ/Serban et al. - 2018 - Adversarial Examples - A Complete Characterisation.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/9M4NT4XC/1810.html:text/html}
}

@article{hu_parabank:_2019,
	title = {{ParaBank}: {Monolingual} {Bitext} {Generation} and {Sentential} {Paraphrasing} via {Lexically}-constrained {Neural} {Machine} {Translation}},
	shorttitle = {{ParaBank}},
	url = {http://arxiv.org/abs/1901.03644},
	abstract = {We present ParaBank, a large-scale English paraphrase dataset that surpasses prior work in both quantity and quality. Following the approach of ParaNMT, we train a Czech-English neural machine translation (NMT) system to generate novel paraphrases of English reference sentences. By adding lexical constraints to the NMT decoding procedure, however, we are able to produce multiple high-quality sentential paraphrases per source sentence, yielding an English paraphrase resource with more than 4 billion generated tokens and exhibiting greater lexical diversity. Using human judgments, we also demonstrate that ParaBank's paraphrases improve over ParaNMT on both semantic similarity and fluency. Finally, we use ParaBank to train a monolingual NMT model with the same support for lexically-constrained decoding for sentence rewriting tasks.},
	urldate = {2019-06-05},
	journal = {arXiv:1901.03644 [cs]},
	author = {Hu, J. Edward and Rudinger, Rachel and Post, Matt and Van Durme, Benjamin},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.03644},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1901.03644 PDF:/Users/tiffanychien/Zotero/storage/JVEW66FP/Hu et al. - 2019 - ParaBank Monolingual Bitext Generation and Senten.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/MARR5CFZ/1901.html:text/html}
}

@article{alshemali_text_nodate,
	title = {(text) {Adversarial} {Attacks} to {Deep} {Neural} {Networks} in {NLP}: {A} {Survey}},
	abstract = {Deep learning models have achieved great success in solving a variety of natural language processing (NLP) problems. However, an ever-growing body of research illustrates their vulnerability to adversarial examples – inputs modiﬁed by introducing small perturbations to deliberately fool a target model into outputting incorrect results. This vulnerability to adversarial examples has become one of the main hurdles in applying deep neural networks in safety-critical environments. This paper presents a comprehensive survey of adversarial attacks in the ﬁeld of NLP. In this survey, we consider contemporary research on the usage of adversarial examples to foil DNNs and present an exhaustive overview of the methods for creating adversarial texts.},
	language = {en},
	author = {Alshemali, Basemah and Kalita, Jugal},
	pages = {83},
	file = {nlp_Whole_Survey.pdf:/Users/tiffanychien/Documents/colorado/nlp_Whole_Survey.pdf:application/pdf}
}

@inproceedings{jia_adversarial_2017,
	address = {Copenhagen, Denmark},
	title = {Adversarial {Examples} for {Evaluating} {Reading} {Comprehension} {Systems}},
	url = {http://aclweb.org/anthology/D17-1215},
	doi = {10.18653/v1/D17-1215},
	abstract = {Standard accuracy metrics indicate that reading comprehension systems are making rapid progress, but the extent to which these systems truly understand language remains unclear. To reward systems with real language understanding abilities, we propose an adversarial evaluation scheme for the Stanford Question Answering Dataset (SQuAD). Our method tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences, which are automatically generated to distract computer systems without changing the correct answer or misleading humans. In this adversarial setting, the accuracy of sixteen published models drops from an average of 75\% F1 score to 36\%; when the adversary is allowed to add ungrammatical sequences of words, average accuracy on four models decreases further to 7\%. We hope our insights will motivate the development of new models that understand language more precisely.},
	language = {en},
	urldate = {2019-06-05},
	booktitle = {Proceedings of the 2017 {Conference} on {Empirical} {Methods} in {Natural}           {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Jia, Robin and Liang, Percy},
	year = {2017},
	pages = {2021--2031},
	file = {jia liang 13 adding sentences.pdf:/Users/tiffanychien/Documents/colorado/jia liang 13 adding sentences.pdf:application/pdf}
}

@article{ribeiro_semantically_2018,
	title = {Semantically {Equivalent} {Adversarial} {Rules} for {Debugging} {NLP} models},
	abstract = {Complex machine learning models for NLP are often brittle, making different predictions for input instances that are extremely similar semantically. To automatically detect this behavior for individual instances, we present semantically equivalent adversaries (SEAs) – semantic-preserving perturbations that induce changes in the model’s predictions. We generalize these adversaries into semantically equivalent adversarial rules (SEARs) – simple, universal replacement rules that induce adversaries on many instances. We demonstrate the usefulness and ﬂexibility of SEAs and SEARs by detecting bugs in black-box state-of-the-art models for three domains: machine comprehension, visual questionanswering, and sentiment analysis. Via user studies, we demonstrate that we generate high-quality local adversaries for more instances than humans, and that SEARs induce four times as many mistakes as the bugs discovered by human experts. SEARs are also actionable: retraining models using data augmentation signiﬁcantly reduces bugs, while maintaining accuracy.},
	language = {en},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	year = {2018},
	pages = {10},
	file = {ribeiro 53 paraphrase.pdf:/Users/tiffanychien/Documents/colorado/ribeiro 53 paraphrase.pdf:application/pdf}
}

@inproceedings{iyyer_adversarial_2018,
	address = {New Orleans, Louisiana},
	title = {Adversarial {Example} {Generation} with {Syntactically} {Controlled} {Paraphrase} {Networks}},
	url = {https://www.aclweb.org/anthology/N18-1170},
	doi = {10.18653/v1/N18-1170},
	abstract = {We propose syntactically controlled paraphrase networks (SCPNs) and use them to generate adversarial examples. Given a sentence and a target syntactic form (e.g., a constituency parse), SCPNs are trained to produce a paraphrase of the sentence with the desired syntax. We show it is possible to create training data for this task by first doing backtranslation at a very large scale, and then using a parser to label the syntactic transformations that naturally occur during this process. Such data allows us to train a neural encoder-decoder model with extra inputs to specify the target syntax. A combination of automated and human evaluations show that SCPNs generate paraphrases that follow their target specifications without decreasing paraphrase quality when compared to baseline (uncontrolled) paraphrase systems. Furthermore, they are more capable of generating syntactically adversarial examples that both (1) “fool” pretrained models and (2) improve the robustness of these models to syntactic variation when used to augment their training data.},
	urldate = {2019-06-05},
	booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Iyyer, Mohit and Wieting, John and Gimpel, Kevin and Zettlemoyer, Luke},
	month = jun,
	year = {2018},
	pages = {1875--1885},
	file = {Full Text PDF:/Users/tiffanychien/Zotero/storage/2N6QSSLE/Iyyer et al. - 2018 - Adversarial Example Generation with Syntactically .pdf:application/pdf}
}

@inproceedings{khandelwal_sharp_2018,
	address = {Melbourne, Australia},
	title = {Sharp {Nearby}, {Fuzzy} {Far} {Away}: {How} {Neural} {Language} {Models} {Use} {Context}},
	shorttitle = {Sharp {Nearby}, {Fuzzy} {Far} {Away}},
	url = {https://www.aclweb.org/anthology/P18-1027},
	abstract = {We know very little about how neural language models (LM) use prior linguistic context. In this paper, we investigate the role of context in an LSTM LM, through ablation studies. Specifically, we analyze the increase in perplexity when prior context words are shuffled, replaced, or dropped. On two standard datasets, Penn Treebank and WikiText-2, we find that the model is capable of using about 200 tokens of context on average, but sharply distinguishes nearby context (recent 50 tokens) from the distant history. The model is highly sensitive to the order of words within the most recent sentence, but ignores word order in the long-range context (beyond 50 tokens), suggesting the distant past is modeled only as a rough semantic field or topic. We further find that the neural caching model (Grave et al., 2017b) especially helps the LSTM to copy words from within this distant context. Overall, our analysis not only provides a better understanding of how neural LMs use their context, but also sheds light on recent success from cache-based models.},
	urldate = {2019-06-05},
	booktitle = {Proceedings of the 56th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Khandelwal, Urvashi and He, He and Qi, Peng and Jurafsky, Dan},
	month = jul,
	year = {2018},
	pages = {284--294},
	file = {Full Text PDF:/Users/tiffanychien/Zotero/storage/DDNUVEXE/Khandelwal et al. - 2018 - Sharp Nearby, Fuzzy Far Away How Neural Language .pdf:application/pdf}
}

@article{lin_bandlimiting_2019,
	title = {Bandlimiting {Neural} {Networks} {Against} {Adversarial} {Attacks}},
	url = {http://arxiv.org/abs/1905.12797},
	abstract = {In this paper, we study the adversarial attack and defence problem in deep learning from the perspective of Fourier analysis. We first explicitly compute the Fourier transform of deep ReLU neural networks and show that there exist decaying but non-zero high frequency components in the Fourier spectrum of neural networks. We demonstrate that the vulnerability of neural networks towards adversarial samples can be attributed to these insignificant but non-zero high frequency components. Based on this analysis, we propose to use a simple post-averaging technique to smooth out these high frequency components to improve the robustness of neural networks against adversarial attacks. Experimental results on the ImageNet dataset have shown that our proposed method is universally effective to defend many existing adversarial attacking methods proposed in the literature, including FGSM, PGD, DeepFool and C\&W attacks. Our post-averaging method is simple since it does not require any re-training, and meanwhile it can successfully defend over 95\% of the adversarial samples generated by these methods without introducing any significant performance degradation (less than 1\%) on the original clean images.},
	urldate = {2019-06-05},
	journal = {arXiv:1905.12797 [cs, stat]},
	author = {Lin, Yuping and A., Kasra Ahmadi K. and Jiang, Hui},
	month = may,
	year = {2019},
	note = {arXiv: 1905.12797},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, I.1.5, Statistics - Machine Learning},
	file = {arXiv\:1905.12797 PDF:/Users/tiffanychien/Zotero/storage/ZMVK55LU/Lin et al. - 2019 - Bandlimiting Neural Networks Against Adversarial A.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/U5W5LXD2/1905.html:text/html}
}

@article{goodfellow_explaining_2014,
	title = {Explaining and {Harnessing} {Adversarial} {Examples}},
	url = {http://arxiv.org/abs/1412.6572},
	abstract = {Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.},
	urldate = {2019-06-05},
	journal = {arXiv:1412.6572 [cs, stat]},
	author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.6572},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv\:1412.6572 PDF:/Users/tiffanychien/Zotero/storage/GJ5MN7YM/Goodfellow et al. - 2014 - Explaining and Harnessing Adversarial Examples.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/65WXK3FM/1412.html:text/html}
}

@inproceedings{zheng_robust_2018,
	title = {Robust {Detection} of {Adversarial} {Attacks} by {Modeling} the {Intrinsic} {Properties} of {Deep} {Neural} {Networks}},
	abstract = {It has been shown that deep neural network (DNN) based classifiers are vulnerable to human-imperceptive adversarial perturbations which can cause DNN classifiers to output wrong predictions with high confidence. We propose an unsupervised learning approach to detect adversarial inputs without any knowledge of attackers. Our approach tries to capture the intrinsic properties of a DNN classifier and uses them to detect adversarial inputs. The intrinsic properties used in this study are the output distributions of the hidden neurons in a DNN classifier presented with natural images. Our approach can be easily applied to any DNN classifiers or combined with other defense strategies to improve robustness. Experimental results show that our approach demonstrates state-of-the-art robustness in defending black-box and gray-box attacks.},
	booktitle = {{NeurIPS}},
	author = {Zheng, Zhihao and Hong, Pengyu},
	year = {2018},
	keywords = {Approximation algorithm, Artificial neural network, Black box, Gm(m), Iterative method, Learning classifier system, Neural network software, Unsupervised learning},
	file = {Full Text PDF:/Users/tiffanychien/Zotero/storage/46VIRDX5/Zheng and Hong - 2018 - Robust Detection of Adversarial Attacks by Modelin.pdf:application/pdf}
}

@article{belinkov_synthetic_2017,
	title = {Synthetic and {Natural} {Noise} {Both} {Break} {Neural} {Machine} {Translation}},
	url = {http://arxiv.org/abs/1711.02173},
	abstract = {Character-based neural machine translation (NMT) models alleviate out-of-vocabulary issues, learn morphology, and move us closer to completely end-to-end translation systems. Unfortunately, they are also very brittle and easily falter when presented with noisy data. In this paper, we confront NMT models with synthetic and natural sources of noise. We find that state-of-the-art models fail to translate even moderately noisy texts that humans have no trouble comprehending. We explore two approaches to increase model robustness: structure-invariant word representations and robust training on noisy texts. We find that a model based on a character convolutional neural network is able to simultaneously learn representations robust to multiple kinds of noise.},
	urldate = {2019-06-05},
	journal = {arXiv:1711.02173 [cs]},
	author = {Belinkov, Yonatan and Bisk, Yonatan},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.02173},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, I.2.7},
	file = {arXiv\:1711.02173 PDF:/Users/tiffanychien/Zotero/storage/ULQX8VTN/Belinkov and Bisk - 2017 - Synthetic and Natural Noise Both Break Neural Mach.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/MAA2QDAG/1711.html:text/html}
}

@article{mudrakarta_did_2018,
	title = {Did the {Model} {Understand} the {Question}?},
	url = {http://arxiv.org/abs/1805.05492},
	abstract = {We analyze state-of-the-art deep learning models for three tasks: question answering on (1) images, (2) tables, and (3) passages of text. Using the notion of {\textbackslash}emph\{attribution\} (word importance), we find that these deep networks often ignore important question terms. Leveraging such behavior, we perturb questions to craft a variety of adversarial examples. Our strongest attacks drop the accuracy of a visual question answering model from \$61.1{\textbackslash}\%\$ to \$19{\textbackslash}\%\$, and that of a tabular question answering model from \$33.5{\textbackslash}\%\$ to \$3.3{\textbackslash}\%\$. Additionally, we show how attributions can strengthen attacks proposed by Jia and Liang (2017) on paragraph comprehension models. Our results demonstrate that attributions can augment standard measures of accuracy and empower investigation of model performance. When a model is accurate but for the wrong reasons, attributions can surface erroneous logic in the model that indicates inadequacies in the test data.},
	urldate = {2019-06-05},
	journal = {arXiv:1805.05492 [cs]},
	author = {Mudrakarta, Pramod Kaushik and Taly, Ankur and Sundararajan, Mukund and Dhamdhere, Kedar},
	month = may,
	year = {2018},
	note = {arXiv: 1805.05492},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {arXiv\:1805.05492 PDF:/Users/tiffanychien/Zotero/storage/ADHEEYVE/Mudrakarta et al. - 2018 - Did the Model Understand the Question.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/C5KWHZ2H/1805.html:text/html}
}

@article{blohm_comparing_2018,
	title = {Comparing {Attention}-based {Convolutional} and {Recurrent} {Neural} {Networks}: {Success} and {Limitations} in {Machine} {Reading} {Comprehension}},
	shorttitle = {Comparing {Attention}-based {Convolutional} and {Recurrent} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1808.08744},
	abstract = {We propose a machine reading comprehension model based on the compare-aggregate framework with two-staged attention that achieves state-of-the-art results on the MovieQA question answering dataset. To investigate the limitations of our model as well as the behavioral difference between convolutional and recurrent neural networks, we generate adversarial examples to confuse the model and compare to human performance. Furthermore, we assess the generalizability of our model by analyzing its differences to human inference,},
	urldate = {2019-06-05},
	journal = {arXiv:1808.08744 [cs]},
	author = {Blohm, Matthias and Jagfeld, Glorianna and Sood, Ekta and Yu, Xiang and Vu, Ngoc Thang},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.08744},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1808.08744 PDF:/Users/tiffanychien/Zotero/storage/3WXNHGSJ/Blohm et al. - 2018 - Comparing Attention-based Convolutional and Recurr.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/MSFG7MHY/1808.html:text/html}
}

@article{li_visualizing_2015,
	title = {Visualizing and {Understanding} {Neural} {Models} in {NLP}},
	url = {http://arxiv.org/abs/1506.01066},
	abstract = {While neural networks have been successfully applied to many NLP tasks the resulting vector-based models are very difficult to interpret. For example it's not clear how they achieve \{{\textbackslash}em compositionality\}, building sentence meaning from the meanings of words and phrases. In this paper we describe four strategies for visualizing compositionality in neural models for NLP, inspired by similar work in computer vision. We first plot unit values to visualize compositionality of negation, intensification, and concessive clauses, allow us to see well-known markedness asymmetries in negation. We then introduce three simple and straightforward methods for visualizing a unit's \{{\textbackslash}em salience\}, the amount it contributes to the final composed meaning: (1) gradient back-propagation, (2) the variance of a token from the average word node, (3) LSTM-style gates that measure information flow. We test our methods on sentiment using simple recurrent nets and LSTMs. Our general-purpose methods may have wide applications for understanding compositionality and other semantic properties of deep networks , and also shed light on why LSTMs outperform simple recurrent nets,},
	urldate = {2019-06-05},
	journal = {arXiv:1506.01066 [cs]},
	author = {Li, Jiwei and Chen, Xinlei and Hovy, Eduard and Jurafsky, Dan},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.01066},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1506.01066 PDF:/Users/tiffanychien/Zotero/storage/E4AVS37U/Li et al. - 2015 - Visualizing and Understanding Neural Models in NLP.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/B97WQVK6/1506.html:text/html}
}

@article{bowman_generating_2015,
	title = {Generating {Sentences} from a {Continuous} {Space}},
	url = {http://arxiv.org/abs/1511.06349},
	abstract = {The standard recurrent neural network language model (RNNLM) generates sentences one word at a time and does not work from an explicit global sentence representation. In this work, we introduce and study an RNN-based variational autoencoder generative model that incorporates distributed latent representations of entire sentences. This factorization allows it to explicitly model holistic properties of sentences such as style, topic, and high-level syntactic features. Samples from the prior over these sentence representations remarkably produce diverse and well-formed sentences through simple deterministic decoding. By examining paths through this latent space, we are able to generate coherent novel sentences that interpolate between known sentences. We present techniques for solving the difficult learning problem presented by this model, demonstrate its effectiveness in imputing missing words, explore many interesting properties of the model's latent sentence space, and present negative results on the use of the model in language modeling.},
	urldate = {2019-06-05},
	journal = {arXiv:1511.06349 [cs]},
	author = {Bowman, Samuel R. and Vilnis, Luke and Vinyals, Oriol and Dai, Andrew M. and Jozefowicz, Rafal and Bengio, Samy},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.06349},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv\:1511.06349 PDF:/Users/tiffanychien/Zotero/storage/EVIPJG5L/Bowman et al. - 2015 - Generating Sentences from a Continuous Space.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/GCW5YYHF/1511.html:text/html}
}

@article{gil_white--black:_2019,
	title = {White-to-{Black}: {Efficient} {Distillation} of {Black}-{Box} {Adversarial} {Attacks}},
	shorttitle = {White-to-{Black}},
	url = {http://arxiv.org/abs/1904.02405},
	abstract = {Adversarial examples are important for understanding the behavior of neural models, and can improve their robustness through adversarial training. Recent work in natural language processing generated adversarial examples by assuming white-box access to the attacked model, and optimizing the input directly against it (Ebrahimi et al., 2018). In this work, we show that the knowledge implicit in the optimization procedure can be distilled into another more efficient neural network. We train a model to emulate the behavior of a white-box attack and show that it generalizes well across examples. Moreover, it reduces adversarial example generation time by 19x-39x. We also show that our approach transfers to a black-box setting, by attacking The Google Perspective API and exposing its vulnerability. Our attack flips the API-predicted label in 42{\textbackslash}\% of the generated examples, while humans maintain high-accuracy in predicting the gold label.},
	urldate = {2019-06-05},
	journal = {arXiv:1904.02405 [cs, stat]},
	author = {Gil, Yotam and Chai, Yoav and Gorodissky, Or and Berant, Jonathan},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.02405},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv\:1904.02405 PDF:/Users/tiffanychien/Zotero/storage/NB7FHNKG/Gil et al. - 2019 - White-to-Black Efficient Distillation of Black-Bo.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/FWYCMSG8/1904.html:text/html}
}

@inproceedings{papernot_distillation_2016,
	title = {Distillation as a {Defense} to {Adversarial} {Perturbations} {Against} {Deep} {Neural} {Networks}},
	doi = {10.1109/SP.2016.41},
	abstract = {Deep learning algorithms have been shown to perform extremely well on many classical machine learning problems. However, recent studies have shown that deep learning, like other machine learning techniques, is vulnerable to adversarial samples: inputs crafted to force a deep neural network (DNN) to provide adversary-selected outputs. Such attacks can seriously undermine the security of the system supported by the DNN, sometimes with devastating consequences. For example, autonomous vehicles can be crashed, illicit or illegal content can bypass content filters, or biometric authentication systems can be manipulated to allow improper access. In this work, we introduce a defensive mechanism called defensive distillation to reduce the effectiveness of adversarial samples on DNNs. We analytically investigate the generalizability and robustness properties granted by the use of defensive distillation when training DNNs. We also empirically study the effectiveness of our defense mechanisms on two DNNs placed in adversarial settings. The study shows that defensive distillation can reduce effectiveness of sample creation from 95\% to less than 0.5\% on a studied DNN. Such dramatic gains can be explained by the fact that distillation leads gradients used in adversarial sample creation to be reduced by a factor of 1030. We also find that distillation increases the average minimum number of features that need to be modified to create adversarial samples by about 800\% on one of the DNNs we tested.},
	booktitle = {2016 {IEEE} {Symposium} on {Security} and {Privacy} ({SP})},
	author = {Papernot, N. and McDaniel, P. and Wu, X. and Jha, S. and Swami, A.},
	month = may,
	year = {2016},
	keywords = {adversarial perturbations, adversarial sample creation, Automobiles, Computational modeling, Computer architecture, deep learning algorithms, deep neural networks, defensive distillation mechanism, DNN, learning (artificial intelligence), Machine learning, machine learning problems, neural nets, Neural networks, security, Security, security of data, Training},
	pages = {582--597},
	file = {IEEE Xplore Abstract Record:/Users/tiffanychien/Zotero/storage/4K5DHCWG/7546524.html:text/html;IEEE Xplore Full Text PDF:/Users/tiffanychien/Zotero/storage/79YW2L4M/Papernot et al. - 2016 - Distillation as a Defense to Adversarial Perturbat.pdf:application/pdf}
}

@article{cifka_are_2018,
	title = {Are {BLEU} and {Meaning} {Representation} in {Opposition}?},
	url = {http://arxiv.org/abs/1805.06536},
	abstract = {One of possible ways of obtaining continuous-space sentence representations is by training neural machine translation (NMT) systems. The recent attention mechanism however removes the single point in the neural network from which the source sentence representation can be extracted. We propose several variations of the attentive NMT architecture bringing this meeting point back. Empirical evaluation suggests that the better the translation quality, the worse the learned sentence representations serve in a wide range of classification and similarity tasks.},
	urldate = {2019-06-06},
	journal = {arXiv:1805.06536 [cs]},
	author = {Cífka, Ondřej and Bojar, Ondřej},
	month = may,
	year = {2018},
	note = {arXiv: 1805.06536},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1805.06536 PDF:/Users/tiffanychien/Zotero/storage/IRITMCA4/Cífka and Bojar - 2018 - Are BLEU and Meaning Representation in Opposition.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/NJX3ZG72/1805.html:text/html}
}

@article{cifka_are_2018-1,
	title = {Are {BLEU} and {Meaning} {Representation} in {Opposition}?},
	url = {http://arxiv.org/abs/1805.06536},
	abstract = {One of possible ways of obtaining continuous-space sentence representations is by training neural machine translation (NMT) systems. The recent attention mechanism however removes the single point in the neural network from which the source sentence representation can be extracted. We propose several variations of the attentive NMT architecture bringing this meeting point back. Empirical evaluation suggests that the better the translation quality, the worse the learned sentence representations serve in a wide range of classification and similarity tasks.},
	urldate = {2019-06-06},
	journal = {arXiv:1805.06536 [cs]},
	author = {Cífka, Ondřej and Bojar, Ondřej},
	month = may,
	year = {2018},
	note = {arXiv: 1805.06536},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1805.06536 PDF:/Users/tiffanychien/Zotero/storage/ZRQGILG2/Cífka and Bojar - 2018 - Are BLEU and Meaning Representation in Opposition.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/ZGE585P9/1805.html:text/html}
}

@article{arora_simple_2016,
	title = {A {Simple} but {Tough}-to-{Beat} {Baseline} for {Sentence} {Embeddings}},
	url = {https://openreview.net/forum?id=SyK00v5xx},
	abstract = {The success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs....},
	urldate = {2019-06-06},
	author = {Arora, Sanjeev and Liang, Yingyu and Ma, Tengyu},
	month = nov,
	year = {2016},
	file = {Full Text PDF:/Users/tiffanychien/Zotero/storage/68FB3K3J/Arora et al. - 2016 - A Simple but Tough-to-Beat Baseline for Sentence E.pdf:application/pdf;Snapshot:/Users/tiffanychien/Zotero/storage/N8LLLRH7/forum.html:text/html}
}

@inproceedings{templeton_exploring_2018,
	title = {Exploring {Sentence} {Vector} {Spaces} through {Automatic} {Summarization}},
	doi = {10.1109/ICMLA.2018.00016},
	abstract = {Given vector representations for individual words, it is necessary to compute vector representations of sentences for many applications in a compositional manner, often using artificial neural networks. Relatively little work has explored the internal structure and properties of such sentence vectors. In this paper, we explore the properties of sentence vectors in the context of automatic summarization. In particular, we show that cosine similarity between sentence vectors and document vectors is strongly correlated with sentence importance and that vector semantics can identify and correct gaps between the sentences chosen so far and the document. In addition, we identify specific dimensions which are linked to effective summaries. To our knowledge, this is the first time specific dimensions of sentence embeddings have been connected to sentence properties. We also compare the features of different methods of sentence embeddings. Many of these insights have applications in uses of sentence embeddings far beyond summarization.},
	booktitle = {2018 17th {IEEE} {International} {Conference} on {Machine} {Learning} and {Applications} ({ICMLA})},
	author = {Templeton, A. and Kalita, J.},
	month = dec,
	year = {2018},
	keywords = {artificial neural networks, automatic summarization, Computational modeling, document handling, document vectors, Force, natural language processing, Natural Language Processing, neural nets, Neural networks, NLP, Redundancy, Semantics, sentence embeddings, sentence importance, sentence properties, sentence vector spaces, sentence vectors, Sentence Vectors, Space exploration, Summarization, Task analysis, vector representations, vector semantics, vectors},
	pages = {55--60},
	file = {IEEE Xplore Abstract Record:/Users/tiffanychien/Zotero/storage/2MHYCYRN/8614041.html:text/html;IEEE Xplore Full Text PDF:/Users/tiffanychien/Zotero/storage/WZCACHMF/Templeton and Kalita - 2018 - Exploring Sentence Vector Spaces through Automatic.pdf:application/pdf}
}

@article{cer_universal_2018,
	title = {Universal {Sentence} {Encoder}},
	url = {http://arxiv.org/abs/1803.11175},
	abstract = {We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.},
	urldate = {2019-06-06},
	journal = {arXiv:1803.11175 [cs]},
	author = {Cer, Daniel and Yang, Yinfei and Kong, Sheng-yi and Hua, Nan and Limtiaco, Nicole and John, Rhomni St and Constant, Noah and Guajardo-Cespedes, Mario and Yuan, Steve and Tar, Chris and Sung, Yun-Hsuan and Strope, Brian and Kurzweil, Ray},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.11175},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1803.11175 PDF:/Users/tiffanychien/Zotero/storage/RAUTPW97/Cer et al. - 2018 - Universal Sentence Encoder.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/ZHMYPFXS/1803.html:text/html}
}

@article{conneau_supervised_2017,
	title = {Supervised {Learning} of {Universal} {Sentence} {Representations} from {Natural} {Language} {Inference} {Data}},
	url = {http://arxiv.org/abs/1705.02364},
	abstract = {Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available.},
	urldate = {2019-06-06},
	journal = {arXiv:1705.02364 [cs]},
	author = {Conneau, Alexis and Kiela, Douwe and Schwenk, Holger and Barrault, Loic and Bordes, Antoine},
	month = may,
	year = {2017},
	note = {arXiv: 1705.02364},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1705.02364 PDF:/Users/tiffanychien/Zotero/storage/B4UHKUQW/Conneau et al. - 2017 - Supervised Learning of Universal Sentence Represen.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/F8GYTQ3Y/1705.html:text/html}
}

@article{quan_efficient_2019,
	title = {An {Efficient} {Framework} for {Sentence} {Similarity} {Modeling}},
	volume = {27},
	issn = {2329-9290},
	doi = {10.1109/TASLP.2019.2899494},
	abstract = {Sentence similarity modeling lies at the core of many natural language processing applications, and thus has received much attention. Owing to the success of word embeddings, recently, popular neural network methods achieved sentence embedding. Most of them focused on learning semantic information and modeling it as a continuous vector, yet the syntactic information of sentences has not been fully exploited. On the other hand, prior works have shown the benefits of structured trees that include syntactic information, while few methods in this branch utilized the advantages of word embeddings and another powerful technique-attention weight mechanism. This paper suggests to absorb their advantages by merging these techniques in a unified structure, dubbed as attention constituency vector tree (ACVT). Meanwhile, this paper develops a new tree kernel, known as ACVT kernel, which is tailored for sentence similarity measure based on the proposed structure. The experimental results, based on 19 widely used semantic textual similarity datasets, demonstrate that our model is effective and competitive, when compared against state-of-the-art models. Additionally, the experimental results validate that many attention weight mechanisms and word embedding techniques can be seamlessly integrated into our model, demonstrating the robustness and universality of our model.},
	number = {4},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Quan, Z. and Wang, Z. and Le, Y. and Yao, B. and Li, K. and Yin, J.},
	month = apr,
	year = {2019},
	keywords = {attention constituency vector tree, attention weight, attention weight mechanisms, Kernel, natural language processing, Natural language processing, natural language processing applications, neural network methods, Neural networks, semantic information, semantic textual similarity datasets, Semantics, sentence embedding, Sentence similarity, sentence similarity measure, sentence similarity modeling, Speech processing, structured trees, syntactic information, syntactic structure, Syntactics, text analysis, tree kernel, trees (mathematics), Vegetation, word embedding, word embedding techniques},
	pages = {853--865},
	file = {IEEE Xplore Abstract Record:/Users/tiffanychien/Zotero/storage/ZGSNU4BE/8642425.html:text/html;IEEE Xplore Full Text PDF:/Users/tiffanychien/Zotero/storage/JV9ELVGR/Quan et al. - 2019 - An Efficient Framework for Sentence Similarity Mod.pdf:application/pdf}
}

@inproceedings{glockner_breaking_2018,
	address = {Melbourne, Australia},
	title = {Breaking {NLI} {Systems} with {Sentences} that {Require} {Simple} {Lexical} {Inferences}},
	url = {https://www.aclweb.org/anthology/P18-2103},
	abstract = {We create a new NLI test set that shows the deficiency of state-of-the-art models in inferences that require lexical and world knowledge. The new examples are simpler than the SNLI test set, containing sentences that differ by at most one word from sentences in the training set. Yet, the performance on the new test set is substantially worse across systems trained on SNLI, demonstrating that these systems are limited in their generalization ability, failing to capture many simple inferences.},
	urldate = {2019-06-06},
	booktitle = {Proceedings of the 56th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Glockner, Max and Shwartz, Vered and Goldberg, Yoav},
	month = jul,
	year = {2018},
	pages = {650--655},
	file = {Full Text PDF:/Users/tiffanychien/Zotero/storage/GCQVC7GP/Glockner et al. - 2018 - Breaking NLI Systems with Sentences that Require S.pdf:application/pdf}
}

@inproceedings{silva_exploring_2019,
	address = {Palo Alto, California USA},
	title = {Exploring {Knowledge} {Graphs} in an {Interpretable} {Composite} {Approach} for {Text} {Entailment}},
	url = {https://www.alexandria.unisg.ch/255897/},
	abstract = {Recognizing textual entailment is a key task for many seman- tic applications, such as Question Answering, Text Summa- rization, and Information Extraction, among others. Entail- ment scenarios can range from a simple syntactic variation to more complex semantic relationships between pieces of text, but most approaches try a one-size-fits-all solution that usually favors some scenario to the detriment of another. We propose a composite approach for recognizing text entailment which analyzes the entailment pair to decide whether it must be resolved syntactically or semantically. We also make the answer interpretable: whenever an entailment is solved se- mantically, we explore a knowledge base composed of structured lexical definitions to generate natural language human- like justifications, explaining the semantic relationship hold- ing between the pieces of text. Besides outperforming well- established entailment algorithms, our composite approach gives an important step towards Explainable AI, using world knowledge to make the semantic reasoning process explicit and understandable.},
	language = {en},
	urldate = {2019-06-06},
	booktitle = {Thirty-{Third} {AAAI} conference on artificial intelligence},
	publisher = {AAAI Press},
	author = {Silva, Vivian and Freitas, Andre and Handschuh, Siegfried},
	month = jan,
	year = {2019},
	file = {Full Text PDF:/Users/tiffanychien/Zotero/storage/HVZRHSRA/Silva et al. - 2019 - Exploring Knowledge Graphs in an Interpretable Com.pdf:application/pdf;Snapshot:/Users/tiffanychien/Zotero/storage/3H5TSKUK/255897.html:text/html}
}

@article{liu_nlize:_2019,
	title = {{NLIZE}: {A} {Perturbation}-{Driven} {Visual} {Interrogation} {Tool} for {Analyzing} and {Interpreting} {Natural} {Language} {Inference} {Models}},
	volume = {25},
	issn = {1077-2626},
	shorttitle = {{NLIZE}},
	doi = {10.1109/TVCG.2018.2865230},
	abstract = {With the recent advances in deep learning, neural network models have obtained state-of-the-art performances for many linguistic tasks in natural language processing. However, this rapid progress also brings enormous challenges. The opaque nature of a neural network model leads to hard-to-debug-systems and difficult-to-interpret mechanisms. Here, we introduce a visualization system that, through a tight yet flexible integration between visualization elements and the underlying model, allows a user to interrogate the model by perturbing the input, internal state, and prediction while observing changes in other parts of the pipeline. We use the natural language inference problem as an example to illustrate how a perturbation-driven paradigm can help domain experts assess the potential limitation of a model, probe its inner states, and interpret and form hypotheses about fundamental model mechanisms such as attention.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Liu, S. and Li, Z. and Li, T. and Srikumar, V. and Pascucci, V. and Bremer, P.},
	month = jan,
	year = {2019},
	keywords = {Analytical models, Attention Visualization, Computational modeling, data visualisation, deep learning, hard-to-debug-systems, inference mechanisms, Interpretable Machine Learning, learning (artificial intelligence), linguistic tasks, Natural Language Inference, natural language inference problem, natural language processing, Natural Language Processing, Natural languages, neural nets, neural network model, Neural networks, perturbation-driven visual interrogation tool, Predictive models, Task analysis, Visualization, visualization system},
	pages = {651--660},
	file = {IEEE Xplore Abstract Record:/Users/tiffanychien/Zotero/storage/TFPZ2372/8454904.html:text/html;IEEE Xplore Full Text PDF:/Users/tiffanychien/Zotero/storage/KFJGEATY/Liu et al. - 2019 - NLIZE A Perturbation-Driven Visual Interrogation .pdf:application/pdf}
}

@article{liu_inoculation_2019,
	title = {Inoculation by {Fine}-{Tuning}: {A} {Method} for {Analyzing} {Challenge} {Datasets}},
	shorttitle = {Inoculation by {Fine}-{Tuning}},
	url = {http://arxiv.org/abs/1904.02668},
	abstract = {Several datasets have recently been constructed to expose brittleness in models trained on existing benchmarks. While model performance on these challenge datasets is significantly lower compared to the original benchmark, it is unclear what particular weaknesses they reveal. For example, a challenge dataset may be difficult because it targets phenomena that current models cannot capture, or because it simply exploits blind spots in a model's specific training set. We introduce inoculation by fine-tuning, a new analysis method for studying challenge datasets by exposing models (the metaphorical patient) to a small amount of data from the challenge dataset (a metaphorical pathogen) and assessing how well they can adapt. We apply our method to analyze the NLI "stress tests" (Naik et al., 2018) and the Adversarial SQuAD dataset (Jia and Liang, 2017). We show that after slight exposure, some of these datasets are no longer challenging, while others remain difficult. Our results indicate that failures on challenge datasets may lead to very different conclusions about models, training datasets, and the challenge datasets themselves.},
	urldate = {2019-06-06},
	journal = {arXiv:1904.02668 [cs]},
	author = {Liu, Nelson F. and Schwartz, Roy and Smith, Noah A.},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.02668},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1904.02668 PDF:/Users/tiffanychien/Zotero/storage/Y8QTHP8T/Liu et al. - 2019 - Inoculation by Fine-Tuning A Method for Analyzing.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/BDEMUAVU/1904.html:text/html}
}

@article{zhao_generating_2017,
	title = {Generating {Natural} {Adversarial} {Examples}},
	url = {http://arxiv.org/abs/1710.11342},
	abstract = {Due to their complex nature, it is hard to characterize the ways in which machine learning models can misbehave or be exploited when deployed. Recent work on adversarial examples, i.e. inputs with minor perturbations that result in substantially different model predictions, is helpful in evaluating the robustness of these models by exposing the adversarial scenarios where they fail. However, these malicious perturbations are often unnatural, not semantically meaningful, and not applicable to complicated domains such as language. In this paper, we propose a framework to generate natural and legible adversarial examples that lie on the data manifold, by searching in semantic space of dense and continuous data representation, utilizing the recent advances in generative adversarial networks. We present generated adversaries to demonstrate the potential of the proposed approach for black-box classifiers for a wide range of applications such as image classification, textual entailment, and machine translation. We include experiments to show that the generated adversaries are natural, legible to humans, and useful in evaluating and analyzing black-box classifiers.},
	urldate = {2019-06-06},
	journal = {arXiv:1710.11342 [cs]},
	author = {Zhao, Zhengli and Dua, Dheeru and Singh, Sameer},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.11342},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {arXiv\:1710.11342 PDF:/Users/tiffanychien/Zotero/storage/VKVT3RJ4/Zhao et al. - 2017 - Generating Natural Adversarial Examples.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/8ELMJFCA/1710.html:text/html}
}

@article{kim_probing_2019,
	title = {Probing {What} {Different} {NLP} {Tasks} {Teach} {Machines} about {Function} {Word} {Comprehension}},
	url = {http://arxiv.org/abs/1904.11544},
	abstract = {We introduce a set of nine challenge tasks that test for the understanding of function words. These tasks are created by structurally mutating sentences from existing datasets to target the comprehension of specific types of function words (e.g., prepositions, wh-words). Using these probing tasks, we explore the effects of various pretraining objectives for sentence encoders (e.g., language modeling, CCG supertagging and natural language inference (NLI)) on the learned representations. Our results show that pretraining on CCG---our most syntactic objective---performs the best on average across our probing tasks, suggesting that syntactic knowledge helps function word comprehension. Language modeling also shows strong performance, supporting its widespread use for pretraining state-of-the-art NLP models. Overall, no pretraining objective dominates across the board, and our function word probing tasks highlight several intuitive differences between pretraining objectives, e.g., that NLI helps the comprehension of negation.},
	urldate = {2019-06-06},
	journal = {arXiv:1904.11544 [cs]},
	author = {Kim, Najoung and Patel, Roma and Poliak, Adam and Wang, Alex and Xia, Patrick and McCoy, R. Thomas and Tenney, Ian and Ross, Alexis and Linzen, Tal and Van Durme, Benjamin and Bowman, Samuel R. and Pavlick, Ellie},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.11544},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1904.11544 PDF:/Users/tiffanychien/Zotero/storage/YV32V9KP/Kim et al. - 2019 - Probing What Different NLP Tasks Teach Machines ab.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/PTBZSRXN/1904.html:text/html}
}

@article{mccoy_right_2019,
	title = {Right for the {Wrong} {Reasons}: {Diagnosing} {Syntactic} {Heuristics} in {Natural} {Language} {Inference}},
	shorttitle = {Right for the {Wrong} {Reasons}},
	url = {http://arxiv.org/abs/1902.01007},
	abstract = {A machine learning system can score well on a given test set by relying on heuristics that are effective for frequent example types but break down in more challenging cases. We study this issue within natural language inference (NLI), the task of determining whether one sentence entails another. We hypothesize that statistical NLI models may adopt three fallible syntactic heuristics: the lexical overlap heuristic, the subsequence heuristic, and the constituent heuristic. To determine whether models have adopted these heuristics, we introduce a controlled evaluation set called HANS (Heuristic Analysis for NLI Systems), which contains many examples where the heuristics fail. We find that models trained on MNLI, including the state-of-the-art model BERT, perform very poorly on HANS, suggesting that they have indeed adopted these heuristics. We conclude that there is substantial room for improvement in NLI systems, and that the HANS dataset can motivate and measure progress in this area.},
	urldate = {2019-06-06},
	journal = {arXiv:1902.01007 [cs]},
	author = {McCoy, R. Thomas and Pavlick, Ellie and Linzen, Tal},
	month = feb,
	year = {2019},
	note = {arXiv: 1902.01007},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1902.01007 PDF:/Users/tiffanychien/Zotero/storage/9PA3YE85/McCoy et al. - 2019 - Right for the Wrong Reasons Diagnosing Syntactic .pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/K3MFPTPM/1902.html:text/html}
}

@article{naik_stress_2018,
	title = {Stress {Test} {Evaluation} for {Natural} {Language} {Inference}},
	url = {http://arxiv.org/abs/1806.00692},
	abstract = {Natural language inference (NLI) is the task of determining if a natural language hypothesis can be inferred from a given premise in a justifiable manner. NLI was proposed as a benchmark task for natural language understanding. Existing models perform well at standard datasets for NLI, achieving impressive results across different genres of text. However, the extent to which these models understand the semantic content of sentences is unclear. In this work, we propose an evaluation methodology consisting of automatically constructed "stress tests" that allow us to examine whether systems have the ability to make real inferential decisions. Our evaluation of six sentence-encoder models on these stress tests reveals strengths and weaknesses of these models with respect to challenging linguistic phenomena, and suggests important directions for future work in this area.},
	urldate = {2019-06-06},
	journal = {arXiv:1806.00692 [cs]},
	author = {Naik, Aakanksha and Ravichander, Abhilasha and Sadeh, Norman and Rose, Carolyn and Neubig, Graham},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.00692},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1806.00692 PDF:/Users/tiffanychien/Zotero/storage/7UZSXMXW/Naik et al. - 2018 - Stress Test Evaluation for Natural Language Infere.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/EWMNB6TZ/1806.html:text/html}
}

@article{michel_evaluation_2019,
	title = {On {Evaluation} of {Adversarial} {Perturbations} for {Sequence}-to-{Sequence} {Models}},
	url = {http://arxiv.org/abs/1903.06620},
	abstract = {Adversarial examples --- perturbations to the input of a model that elicit large changes in the output --- have been shown to be an effective way of assessing the robustness of sequence-to-sequence (seq2seq) models. However, these perturbations only indicate weaknesses in the model if they do not change the input so significantly that it legitimately results in changes in the expected output. This fact has largely been ignored in the evaluations of the growing body of related literature. Using the example of untargeted attacks on machine translation (MT), we propose a new evaluation framework for adversarial attacks on seq2seq models that takes the semantic equivalence of the pre- and post-perturbation input into account. Using this framework, we demonstrate that existing methods may not preserve meaning in general, breaking the aforementioned assumption that source side perturbations should not result in changes in the expected output. We further use this framework to demonstrate that adding additional constraints on attacks allows for adversarial perturbations that are more meaning-preserving, but nonetheless largely change the output sequence. Finally, we show that performing untargeted adversarial training with meaning-preserving attacks is beneficial to the model in terms of adversarial robustness, without hurting test performance. A toolkit implementing our evaluation framework is released at https://github.com/pmichel31415/teapot-nlp.},
	urldate = {2019-06-06},
	journal = {arXiv:1903.06620 [cs]},
	author = {Michel, Paul and Li, Xian and Neubig, Graham and Pino, Juan Miguel},
	month = mar,
	year = {2019},
	note = {arXiv: 1903.06620},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1903.06620 PDF:/Users/tiffanychien/Zotero/storage/WKWZ6XUC/Michel et al. - 2019 - On Evaluation of Adversarial Perturbations for Seq.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/4FT964XE/1903.html:text/html}
}

@article{logeswaran_efficient_2018,
	title = {An efficient framework for learning sentence representations},
	url = {http://arxiv.org/abs/1803.02893},
	abstract = {In this work we propose a simple and efficient framework for learning sentence representations from unlabelled data. Drawing inspiration from the distributional hypothesis and recent work on learning sentence representations, we reformulate the problem of predicting the context in which a sentence appears as a classification problem. Given a sentence and its context, a classifier distinguishes context sentences from other contrastive sentences based on their vector representations. This allows us to efficiently learn different types of encoding functions, and we show that the model learns high-quality sentence representations. We demonstrate that our sentence representations outperform state-of-the-art unsupervised and supervised representation learning methods on several downstream NLP tasks that involve understanding sentence semantics while achieving an order of magnitude speedup in training time.},
	urldate = {2019-06-06},
	journal = {arXiv:1803.02893 [cs]},
	author = {Logeswaran, Lajanugen and Lee, Honglak},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.02893},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv\:1803.02893 PDF:/Users/tiffanychien/Zotero/storage/5VC9CKQ3/Logeswaran and Lee - 2018 - An efficient framework for learning sentence repre.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/C478I5ZY/1803.html:text/html}
}

@article{liu_improving_2019,
	title = {Improving {Multi}-{Task} {Deep} {Neural} {Networks} via {Knowledge} {Distillation} for {Natural} {Language} {Understanding}},
	url = {http://arxiv.org/abs/1904.09482},
	abstract = {This paper explores the use of knowledge distillation to improve a Multi-Task Deep Neural Network (MT-DNN) (Liu et al., 2019) for learning text representations across multiple natural language understanding tasks. Although ensemble learning can improve model performance, serving an ensemble of large DNNs such as MT-DNN can be prohibitively expensive. Here we apply the knowledge distillation method (Hinton et al., 2015) in the multi-task learning setting. For each task, we train an ensemble of different MT-DNNs (teacher) that outperforms any single model, and then train a single MT-DNN (student) via multi-task learning to {\textbackslash}emph\{distill\} knowledge from these ensemble teachers. We show that the distilled MT-DNN significantly outperforms the original MT-DNN on 7 out of 9 GLUE tasks, pushing the GLUE benchmark (single model) to 83.7{\textbackslash}\% (1.5{\textbackslash}\% absolute improvement{\textbackslash}footnote\{ Based on the GLUE leaderboard at https://gluebenchmark.com/leaderboard as of April 1, 2019.\}). The code and pre-trained models will be made publicly available at https://github.com/namisan/mt-dnn.},
	urldate = {2019-06-06},
	journal = {arXiv:1904.09482 [cs]},
	author = {Liu, Xiaodong and He, Pengcheng and Chen, Weizhu and Gao, Jianfeng},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.09482},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1904.09482 PDF:/Users/tiffanychien/Zotero/storage/UJV89VC4/Liu et al. - 2019 - Improving Multi-Task Deep Neural Networks via Know.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/ZURDTH2C/1904.html:text/html}
}

@inproceedings{radford_improving_2018,
	title = {Improving {Language} {Understanding} by {Generative} {Pre}-{Training}},
	abstract = {Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classification. Although large unlabeled text corpora are abundant, labeled data for learning these specific tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative fine-tuning on each specific task. In contrast to previous approaches, we make use of task-aware input transformations during fine-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures specifically crafted for each task, significantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering (RACE), and 1.5\% on textual entailment (MultiNLI).},
	author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
	year = {2018},
	keywords = {Benchmark (computing), Body of uterus, cell transformation, Commonsense knowledge (artificial intelligence), Commonsense reasoning, Discriminative model, Document classification, Language model, Machine learning, Natural language understanding, Question answering, Semantic similarity, Text corpus, Textual entailment, Tracer, Transformers, Unsupervised learning},
	file = {Full Text PDF:/Users/tiffanychien/Zotero/storage/N7IIXLM9/Radford - 2018 - Improving Language Understanding by Generative Pre.pdf:application/pdf}
}

@article{gong_natural_2017,
	title = {Natural {Language} {Inference} over {Interaction} {Space}},
	url = {http://arxiv.org/abs/1709.04348},
	abstract = {Natural Language Inference (NLI) task requires an agent to determine the logical relationship between a natural language premise and a natural language hypothesis. We introduce Interactive Inference Network (IIN), a novel class of neural network architectures that is able to achieve high-level understanding of the sentence pair by hierarchically extracting semantic features from interaction space. We show that an interaction tensor (attention weight) contains semantic information to solve natural language inference, and a denser interaction tensor contains richer semantic information. One instance of such architecture, Densely Interactive Inference Network (DIIN), demonstrates the state-of-the-art performance on large scale NLI copora and large-scale NLI alike corpus. It's noteworthy that DIIN achieve a greater than 20\% error reduction on the challenging Multi-Genre NLI (MultiNLI) dataset with respect to the strongest published system.},
	urldate = {2019-06-06},
	journal = {arXiv:1709.04348 [cs]},
	author = {Gong, Yichen and Luo, Heng and Zhang, Jian},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.04348},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1709.04348 PDF:/Users/tiffanychien/Zotero/storage/D9ZRJPDL/Gong et al. - 2017 - Natural Language Inference over Interaction Space.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/FENMH9A2/1709.html:text/html}
}

@article{shen_generating_2018,
	title = {Generating {Contradictory}, {Neutral}, and {Entailing} {Sentences}},
	url = {http://arxiv.org/abs/1803.02710},
	abstract = {Learning distributed sentence representations remains an interesting problem in the field of Natural Language Processing (NLP). We want to learn a model that approximates the conditional latent space over the representations of a logical antecedent of the given statement. In our paper, we propose an approach to generating sentences, conditioned on an input sentence and a logical inference label. We do this by modeling the different possibilities for the output sentence as a distribution over the latent representation, which we train using an adversarial objective. We evaluate the model using two state-of-the-art models for the Recognizing Textual Entailment (RTE) task, and measure the BLEU scores against the actual sentences as a probe for the diversity of sentences produced by our model. The experiment results show that, given our framework, we have clear ways to improve the quality and diversity of generated sentences.},
	urldate = {2019-06-06},
	journal = {arXiv:1803.02710 [cs]},
	author = {Shen, Yikang and Tan, Shawn and Huang, Chin-Wei and Courville, Aaron},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.02710},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {arXiv\:1803.02710 PDF:/Users/tiffanychien/Zotero/storage/PBHSAWXE/Shen et al. - 2018 - Generating Contradictory, Neutral, and Entailing S.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/S9D36GZH/1803.html:text/html}
}

@article{liu_stochastic_2018,
	title = {Stochastic {Answer} {Networks} for {Natural} {Language} {Inference}},
	url = {http://arxiv.org/abs/1804.07888},
	abstract = {We propose a stochastic answer network (SAN) to explore multi-step inference strategies in Natural Language Inference. Rather than directly predicting the results given the inputs, the model maintains a state and iteratively refines its predictions. Our experiments show that SAN achieves the state-of-the-art results on three benchmarks: Stanford Natural Language Inference (SNLI) dataset, MultiGenre Natural Language Inference (MultiNLI) dataset and Quora Question Pairs dataset.},
	urldate = {2019-06-06},
	journal = {arXiv:1804.07888 [cs]},
	author = {Liu, Xiaodong and Duh, Kevin and Gao, Jianfeng},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.07888},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1804.07888 PDF:/Users/tiffanychien/Zotero/storage/HZ27XGZ8/Liu et al. - 2018 - Stochastic Answer Networks for Natural Language In.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/CYA4KAG8/1804.html:text/html}
}

@article{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2019-06-07},
	journal = {arXiv:1706.03762 [cs]},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = jun,
	year = {2017},
	note = {arXiv: 1706.03762},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv\:1706.03762 PDF:/Users/tiffanychien/Zotero/storage/HI9852FK/Vaswani et al. - 2017 - Attention Is All You Need.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/PEV9CFC3/1706.html:text/html}
}

@article{mccann_learned_2017,
	title = {Learned in {Translation}: {Contextualized} {Word} {Vectors}},
	shorttitle = {Learned in {Translation}},
	url = {http://arxiv.org/abs/1708.00107},
	abstract = {Computer vision has benefited from initializing multiple deep layers with weights pretrained on large supervised training sets like ImageNet. Natural language processing (NLP) typically sees initialization of only the lowest layer of deep models with pretrained word vectors. In this paper, we use a deep LSTM encoder from an attentional sequence-to-sequence model trained for machine translation (MT) to contextualize word vectors. We show that adding these context vectors (CoVe) improves performance over using only unsupervised word and character vectors on a wide variety of common NLP tasks: sentiment analysis (SST, IMDb), question classification (TREC), entailment (SNLI), and question answering (SQuAD). For fine-grained sentiment analysis and entailment, CoVe improves performance of our baseline models to the state of the art.},
	urldate = {2019-06-07},
	journal = {arXiv:1708.00107 [cs]},
	author = {McCann, Bryan and Bradbury, James and Xiong, Caiming and Socher, Richard},
	month = jul,
	year = {2017},
	note = {arXiv: 1708.00107},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv\:1708.00107 PDF:/Users/tiffanychien/Zotero/storage/XPJWQKRT/McCann et al. - 2017 - Learned in Translation Contextualized Word Vector.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/GQRNIT3F/1708.html:text/html}
}

@article{devlin_bert:_2018,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2019-06-07},
	journal = {arXiv:1810.04805 [cs]},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.04805},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1810.04805 PDF:/Users/tiffanychien/Zotero/storage/UZ3YKYUJ/Devlin et al. - 2018 - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/RZVRBUB2/1810.html:text/html}
}

@inproceedings{williams_broad-coverage_2018,
	address = {New Orleans, Louisiana},
	title = {A {Broad}-{Coverage} {Challenge} {Corpus} for {Sentence} {Understanding} through {Inference}},
	url = {http://aclweb.org/anthology/N18-1101},
	doi = {10.18653/v1/N18-1101},
	abstract = {This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difﬁculty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difﬁcult task than does that corpus, despite the two showing similar levels of inter-annotator agreement.},
	language = {en},
	urldate = {2019-06-07},
	booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of           the {Association} for {Computational} {Linguistics}: {Human} {Language}           {Technologies}, {Volume} 1 ({Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Williams, Adina and Nangia, Nikita and Bowman, Samuel},
	year = {2018},
	pages = {1112--1122},
	file = {Williams et al. - 2018 - A Broad-Coverage Challenge Corpus for Sentence Und.pdf:/Users/tiffanychien/Zotero/storage/X5P52BJA/Williams et al. - 2018 - A Broad-Coverage Challenge Corpus for Sentence Und.pdf:application/pdf}
}

@article{vig_visualizing_2019,
	title = {Visualizing {Attention} in {Transformer}-{Based} {Language} {Representation} {Models}},
	url = {http://arxiv.org/abs/1904.02679},
	abstract = {We present an open-source tool for visualizing multi-head self-attention in Transformer-based language representation models. The tool extends earlier work by visualizing attention at three levels of granularity: the attention-head level, the model level, and the neuron level. We describe how each of these views can help to interpret the model, and we demonstrate the tool on the BERT model and the OpenAI GPT-2 model. We also present three use cases for analyzing GPT-2: detecting model bias, identifying recurring patterns, and linking neurons to model behavior.},
	urldate = {2019-06-07},
	journal = {arXiv:1904.02679 [cs, stat]},
	author = {Vig, Jesse},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.02679},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv\:1904.02679 PDF:/Users/tiffanychien/Zotero/storage/NJ5EVYXY/Vig - 2019 - Visualizing Attention in Transformer-Based Languag.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/YWN57GWG/1904.html:text/html}
}

@article{ilyas_adversarial_2019,
	title = {Adversarial {Examples} {Are} {Not} {Bugs}, {They} {Are} {Features}},
	url = {http://arxiv.org/abs/1905.02175},
	abstract = {Adversarial examples have attracted significant attention in machine learning, but the reasons for their existence and pervasiveness remain unclear. We demonstrate that adversarial examples can be directly attributed to the presence of non-robust features: features derived from patterns in the data distribution that are highly predictive, yet brittle and incomprehensible to humans. After capturing these features within a theoretical framework, we establish their widespread existence in standard datasets. Finally, we present a simple setting where we can rigorously tie the phenomena we observe in practice to a misalignment between the (human-specified) notion of robustness and the inherent geometry of the data.},
	urldate = {2019-06-10},
	journal = {arXiv:1905.02175 [cs, stat]},
	author = {Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
	month = may,
	year = {2019},
	note = {arXiv: 1905.02175},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv\:1905.02175 PDF:/Users/tiffanychien/Zotero/storage/289W5QEG/Ilyas et al. - 2019 - Adversarial Examples Are Not Bugs, They Are Featur.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/C98YR34A/1905.html:text/html}
}

@article{ilyas_adversarial_2019-1,
	title = {Adversarial {Examples} {Are} {Not} {Bugs}, {They} {Are} {Features}},
	url = {http://arxiv.org/abs/1905.02175},
	abstract = {Adversarial examples have attracted significant attention in machine learning, but the reasons for their existence and pervasiveness remain unclear. We demonstrate that adversarial examples can be directly attributed to the presence of non-robust features: features derived from patterns in the data distribution that are highly predictive, yet brittle and incomprehensible to humans. After capturing these features within a theoretical framework, we establish their widespread existence in standard datasets. Finally, we present a simple setting where we can rigorously tie the phenomena we observe in practice to a misalignment between the (human-specified) notion of robustness and the inherent geometry of the data.},
	urldate = {2019-06-10},
	journal = {arXiv:1905.02175 [cs, stat]},
	author = {Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
	month = may,
	year = {2019},
	note = {arXiv: 1905.02175},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv\:1905.02175 PDF:/Users/tiffanychien/Zotero/storage/KWBY5XL2/Ilyas et al. - 2019 - Adversarial Examples Are Not Bugs, They Are Featur.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/F4PFXCH8/1905.html:text/html}
}

@article{tang_analysis_2018,
	title = {An {Analysis} of {Attention} {Mechanisms}: {The} {Case} of {Word} {Sense} {Disambiguation} in {Neural} {Machine} {Translation}},
	shorttitle = {An {Analysis} of {Attention} {Mechanisms}},
	url = {http://arxiv.org/abs/1810.07595},
	abstract = {Recent work has shown that the encoder-decoder attention mechanisms in neural machine translation (NMT) are different from the word alignment in statistical machine translation. In this paper, we focus on analyzing encoder-decoder attention mechanisms, in the case of word sense disambiguation (WSD) in NMT models. We hypothesize that attention mechanisms pay more attention to context tokens when translating ambiguous words. We explore the attention distribution patterns when translating ambiguous nouns. Counter-intuitively, we find that attention mechanisms are likely to distribute more attention to the ambiguous noun itself rather than context tokens, in comparison to other nouns. We conclude that attention mechanism is not the main mechanism used by NMT models to incorporate contextual information for WSD. The experimental results suggest that NMT models learn to encode contextual information necessary for WSD in the encoder hidden states. For the attention mechanism in Transformer models, we reveal that the first few layers gradually learn to "align" source and target tokens and the last few layers learn to extract features from the related but unaligned context tokens.},
	urldate = {2019-06-10},
	journal = {arXiv:1810.07595 [cs]},
	author = {Tang, Gongbo and Sennrich, Rico and Nivre, Joakim},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.07595},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1810.07595 PDF:/Users/tiffanychien/Zotero/storage/FCNH556R/Tang et al. - 2018 - An Analysis of Attention Mechanisms The Case of W.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/EF46K939/1810.html:text/html}
}

@article{voita_analyzing_2019,
	title = {Analyzing {Multi}-{Head} {Self}-{Attention}: {Specialized} {Heads} {Do} the {Heavy} {Lifting}, the {Rest} {Can} {Be} {Pruned}},
	shorttitle = {Analyzing {Multi}-{Head} {Self}-{Attention}},
	url = {http://arxiv.org/abs/1905.09418},
	abstract = {Multi-head self-attention is a key component of the Transformer, a state-of-the-art architecture for neural machine translation. In this work we evaluate the contribution made by individual attention heads in the encoder to the overall performance of the model and analyze the roles played by them. We find that the most important and confident heads play consistent and often linguistically-interpretable roles. When pruning heads using a method based on stochastic gates and a differentiable relaxation of the L0 penalty, we observe that specialized heads are last to be pruned. Our novel pruning method removes the vast majority of heads without seriously affecting performance. For example, on the English-Russian WMT dataset, pruning 38 out of 48 encoder heads results in a drop of only 0.15 BLEU.},
	urldate = {2019-06-10},
	journal = {arXiv:1905.09418 [cs]},
	author = {Voita, Elena and Talbot, David and Moiseev, Fedor and Sennrich, Rico and Titov, Ivan},
	month = may,
	year = {2019},
	note = {arXiv: 1905.09418},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1905.09418 PDF:/Users/tiffanychien/Zotero/storage/7XBU7VRI/Voita et al. - 2019 - Analyzing Multi-Head Self-Attention Specialized H.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/8YRBMKPS/1905.html:text/html}
}

@article{michel_are_2019,
	title = {Are {Sixteen} {Heads} {Really} {Better} than {One}?},
	url = {http://arxiv.org/abs/1905.10650},
	abstract = {Attention is a powerful and ubiquitous mechanism for allowing neural models to focus on particular salient pieces of information by taking their weighted average when making predictions. In particular, multi-headed attention is a driving force behind many recent state-of-the-art NLP models such as Transformer-based MT models and BERT. These models apply multiple attention mechanisms in parallel, with each attention "head" potentially focusing on different parts of the input, which makes it possible to express sophisticated functions beyond the simple weighted average. In this paper we make the surprising observation that even if models have been trained using multiple heads, in practice, a large percentage of attention heads can be removed at test time without significantly impacting performance. In fact, some layers can even be reduced to a single head. We further examine greedy algorithms for pruning down models, and the potential speed, memory efficiency, and accuracy improvements obtainable therefrom. Finally, we analyze the results with respect to which parts of the model are more reliant on having multiple heads, and provide precursory evidence that training dynamics play a role in the gains provided by multi-head attention.},
	urldate = {2019-06-10},
	journal = {arXiv:1905.10650 [cs]},
	author = {Michel, Paul and Levy, Omer and Neubig, Graham},
	month = may,
	year = {2019},
	note = {arXiv: 1905.10650},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1905.10650 PDF:/Users/tiffanychien/Zotero/storage/S6H8FX4X/Michel et al. - 2019 - Are Sixteen Heads Really Better than One.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/BUDTNXEU/1905.html:text/html}
}

@article{goldberg_assessing_2019,
	title = {Assessing {BERT}'s {Syntactic} {Abilities}},
	url = {http://arxiv.org/abs/1901.05287},
	abstract = {I assess the extent to which the recently introduced BERT model captures English syntactic phenomena, using (1) naturally-occurring subject-verb agreement stimuli; (2) "coloreless green ideas" subject-verb agreement stimuli, in which content words in natural sentences are randomly replaced with words sharing the same part-of-speech and inflection; and (3) manually crafted stimuli for subject-verb agreement and reflexive anaphora phenomena. The BERT model performs remarkably well on all cases.},
	urldate = {2019-06-10},
	journal = {arXiv:1901.05287 [cs]},
	author = {Goldberg, Yoav},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.05287},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1901.05287 PDF:/Users/tiffanychien/Zotero/storage/JNLAA8JQ/Goldberg - 2019 - Assessing BERT's Syntactic Abilities.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/Z7TUZZ9M/1901.html:text/html}
}

@article{dehghani_universal_2018,
	title = {Universal {Transformers}},
	url = {http://arxiv.org/abs/1807.03819},
	abstract = {Recurrent neural networks (RNNs) sequentially process data by updating their state with each new data point, and have long been the de facto choice for sequence modeling tasks. However, their inherently sequential computation makes them slow to train. Feed-forward and convolutional architectures have recently been shown to achieve superior results on some sequence modeling tasks such as machine translation, with the added advantage that they concurrently process all inputs in the sequence, leading to easy parallelization and faster training times. Despite these successes, however, popular feed-forward sequence models like the Transformer fail to generalize in many simple tasks that recurrent models handle with ease, e.g. copying strings or even simple logical inference when the string or formula lengths exceed those observed at training time. We propose the Universal Transformer (UT), a parallel-in-time self-attentive recurrent sequence model which can be cast as a generalization of the Transformer model and which addresses these issues. UTs combine the parallelizability and global receptive field of feed-forward sequence models like the Transformer with the recurrent inductive bias of RNNs. We also add a dynamic per-position halting mechanism and find that it improves accuracy on several tasks. In contrast to the standard Transformer, under certain assumptions, UTs can be shown to be Turing-complete. Our experiments show that UTs outperform standard Transformers on a wide range of algorithmic and language understanding tasks, including the challenging LAMBADA language modeling task where UTs achieve a new state of the art, and machine translation where UTs achieve a 0.9 BLEU improvement over Transformers on the WMT14 En-De dataset.},
	urldate = {2019-06-10},
	journal = {arXiv:1807.03819 [cs, stat]},
	author = {Dehghani, Mostafa and Gouws, Stephan and Vinyals, Oriol and Uszkoreit, Jakob and Kaiser, Łukasz},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.03819},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv\:1807.03819 PDF:/Users/tiffanychien/Zotero/storage/FJLGJFIN/Dehghani et al. - 2018 - Universal Transformers.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/TTB84MB9/1807.html:text/html}
}

@article{chen_codah:_2019,
	title = {{CODAH}: {An} {Adversarially} {Authored} {Question}-{Answer} {Dataset} for {Common} {Sense}},
	shorttitle = {{CODAH}},
	url = {http://arxiv.org/abs/1904.04365},
	abstract = {Commonsense reasoning is a critical AI capability, but it is difficult to construct challenging datasets that test common sense. Recent neural question answering systems, based on large pre-trained models of language, have already achieved near-human-level performance on commonsense knowledge benchmarks. These systems do not possess human-level common sense, but are able to exploit limitations of the datasets to achieve human-level scores. We introduce the CODAH dataset, an adversarially-constructed evaluation dataset for testing common sense. CODAH forms a challenging extension to the recently-proposed SWAG dataset, which tests commonsense knowledge using sentence-completion questions that describe situations observed in video. To produce a more difficult dataset, we introduce a novel procedure for question acquisition in which workers author questions designed to target weaknesses of state-of-the-art neural question answering systems. Workers are rewarded for submissions that models fail to answer correctly both before and after fine-tuning (in cross-validation). We create 2.8k questions via this procedure and evaluate the performance of multiple state-of-the-art question answering systems on our dataset. We observe a significant gap between human performance, which is 95.3\%, and the performance of the best baseline accuracy of 67.5\% by the BERT-Large model.},
	urldate = {2019-06-10},
	journal = {arXiv:1904.04365 [cs]},
	author = {Chen, Michael and D'Arcy, Mike and Liu, Alisa and Fernandez, Jared and Downey, Doug},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.04365},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv\:1904.04365 PDF:/Users/tiffanychien/Zotero/storage/E7JHY2V7/Chen et al. - 2019 - CODAH An Adversarially Authored Question-Answer D.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/K4NXRC6J/1904.html:text/html}
}

@article{tang_why_2018,
	title = {Why {Self}-{Attention}? {A} {Targeted} {Evaluation} of {Neural} {Machine} {Translation} {Architectures}},
	shorttitle = {Why {Self}-{Attention}?},
	url = {http://arxiv.org/abs/1808.08946},
	abstract = {Recently, non-recurrent architectures (convolutional, self-attentional) have outperformed RNNs in neural machine translation. CNNs and self-attentional networks can connect distant words via shorter network paths than RNNs, and it has been speculated that this improves their ability to model long-range dependencies. However, this theoretical argument has not been tested empirically, nor have alternative explanations for their strong performance been explored in-depth. We hypothesize that the strong performance of CNNs and self-attentional networks could also be due to their ability to extract semantic features from the source text, and we evaluate RNNs, CNNs and self-attention networks on two tasks: subject-verb agreement (where capturing long-range dependencies is required) and word sense disambiguation (where semantic feature extraction is required). Our experimental results show that: 1) self-attentional networks and CNNs do not outperform RNNs in modeling subject-verb agreement over long distances; 2) self-attentional networks perform distinctly better than RNNs and CNNs on word sense disambiguation.},
	urldate = {2019-06-10},
	journal = {arXiv:1808.08946 [cs]},
	author = {Tang, Gongbo and Müller, Mathias and Rios, Annette and Sennrich, Rico},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.08946},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1808.08946 PDF:/Users/tiffanychien/Zotero/storage/4IJ52TZ4/Tang et al. - 2018 - Why Self-Attention A Targeted Evaluation of Neura.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/EQ4MBTQV/1808.html:text/html}
}

@inproceedings{abramova_questioning_2016,
	address = {San Diego, California},
	title = {Questioning {Arbitrariness} in {Language}: a {Data}-{Driven} {Study} of {Conventional} {Iconicity}},
	shorttitle = {Questioning {Arbitrariness} in {Language}},
	url = {https://www.aclweb.org/anthology/N16-1038},
	doi = {10.18653/v1/N16-1038},
	urldate = {2019-06-10},
	booktitle = {Proceedings of the 2016 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Abramova, Ekaterina and Fernández, Raquel},
	month = jun,
	year = {2016},
	pages = {343--352},
	file = {Full Text PDF:/Users/tiffanychien/Zotero/storage/5H7TMIQA/Abramova and Fernández - 2016 - Questioning Arbitrariness in Language a Data-Driv.pdf:application/pdf}
}

@article{bowman_generating_2015-1,
	title = {Generating {Sentences} from a {Continuous} {Space}},
	url = {http://arxiv.org/abs/1511.06349},
	abstract = {The standard recurrent neural network language model (RNNLM) generates sentences one word at a time and does not work from an explicit global sentence representation. In this work, we introduce and study an RNN-based variational autoencoder generative model that incorporates distributed latent representations of entire sentences. This factorization allows it to explicitly model holistic properties of sentences such as style, topic, and high-level syntactic features. Samples from the prior over these sentence representations remarkably produce diverse and well-formed sentences through simple deterministic decoding. By examining paths through this latent space, we are able to generate coherent novel sentences that interpolate between known sentences. We present techniques for solving the difficult learning problem presented by this model, demonstrate its effectiveness in imputing missing words, explore many interesting properties of the model's latent sentence space, and present negative results on the use of the model in language modeling.},
	urldate = {2019-06-10},
	journal = {arXiv:1511.06349 [cs]},
	author = {Bowman, Samuel R. and Vilnis, Luke and Vinyals, Oriol and Dai, Andrew M. and Jozefowicz, Rafal and Bengio, Samy},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.06349},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv\:1511.06349 PDF:/Users/tiffanychien/Zotero/storage/MRZ9IAX2/Bowman et al. - 2015 - Generating Sentences from a Continuous Space.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/IK62KYM8/1511.html:text/html}
}

@inproceedings{bingel_extracting_2016,
	address = {Berlin, Germany},
	title = {Extracting token-level signals of syntactic processing from {fMRI} - with an application to {PoS} induction},
	url = {https://www.aclweb.org/anthology/P16-1071},
	doi = {10.18653/v1/P16-1071},
	urldate = {2019-06-10},
	booktitle = {Proceedings of the 54th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Bingel, Joachim and Barrett, Maria and Søgaard, Anders},
	month = aug,
	year = {2016},
	pages = {747--755},
	file = {Full Text PDF:/Users/tiffanychien/Zotero/storage/2URM77CX/Bingel et al. - 2016 - Extracting token-level signals of syntactic proces.pdf:application/pdf}
}

@article{chen_multi-task_2019,
	title = {A {Multi}-{Task} {Approach} for {Disentangling} {Syntax} and {Semantics} in {Sentence} {Representations}},
	url = {http://arxiv.org/abs/1904.01173},
	abstract = {We propose a generative model for a sentence that uses two latent variables, with one intended to represent the syntax of the sentence and the other to represent its semantics. We show we can achieve better disentanglement between semantic and syntactic representations by training with multiple losses, including losses that exploit aligned paraphrastic sentences and word-order information. We also investigate the effect of moving from bag-of-words to recurrent neural network modules. We evaluate our models as well as several popular pretrained embeddings on standard semantic similarity tasks and novel syntactic similarity tasks. Empirically, we find that the model with the best performing syntactic and semantic representations also gives rise to the most disentangled representations.},
	urldate = {2019-06-10},
	journal = {arXiv:1904.01173 [cs]},
	author = {Chen, Mingda and Tang, Qingming and Wiseman, Sam and Gimpel, Kevin},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.01173},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1904.01173 PDF:/Users/tiffanychien/Zotero/storage/8VJCB9QN/Chen et al. - 2019 - A Multi-Task Approach for Disentangling Syntax and.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/PURHRQNS/1904.html:text/html}
}

@article{zellers_swag:_2018,
	title = {{SWAG}: {A} {Large}-{Scale} {Adversarial} {Dataset} for {Grounded} {Commonsense} {Inference}},
	shorttitle = {{SWAG}},
	url = {http://arxiv.org/abs/1808.05326},
	abstract = {Given a partial description like "she opened the hood of the car," humans can reason about the situation and anticipate what might come next ("then, she examined the engine"). In this paper, we introduce the task of grounded commonsense inference, unifying natural language inference and commonsense reasoning. We present SWAG, a new dataset with 113k multiple choice questions about a rich spectrum of grounded situations. To address the recurring challenges of the annotation artifacts and human biases found in many existing datasets, we propose Adversarial Filtering (AF), a novel procedure that constructs a de-biased dataset by iteratively training an ensemble of stylistic classifiers, and using them to filter the data. To account for the aggressive adversarial filtering, we use state-of-the-art language models to massively oversample a diverse set of potential counterfactuals. Empirical results demonstrate that while humans can solve the resulting inference problems with high accuracy (88\%), various competitive models struggle on our task. We provide comprehensive analysis that indicates significant opportunities for future research.},
	urldate = {2019-06-10},
	journal = {arXiv:1808.05326 [cs]},
	author = {Zellers, Rowan and Bisk, Yonatan and Schwartz, Roy and Choi, Yejin},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.05326},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1808.05326 PDF:/Users/tiffanychien/Zotero/storage/BJBQ57JT/Zellers et al. - 2018 - SWAG A Large-Scale Adversarial Dataset for Ground.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/Z7GUZLWV/1808.html:text/html}
}

@inproceedings{bowman_large_2015,
	address = {Lisbon, Portugal},
	title = {A large annotated corpus for learning natural language inference},
	url = {http://aclweb.org/anthology/D15-1075},
	doi = {10.18653/v1/D15-1075},
	abstract = {Understanding entailment and contradiction is fundamental to understanding natural language, and inference about entailment and contradiction is a valuable testing ground for the development of semantic representations. However, machine learning research in this area has been dramatically limited by the lack of large-scale resources. To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. At 570K pairs, it is two orders of magnitude larger than all other resources of its type. This increase in scale allows lexicalized classiﬁers to outperform some sophisticated existing entailment models, and it allows a neural network-based model to perform competitively on natural language inference benchmarks for the ﬁrst time.},
	language = {en},
	urldate = {2019-06-11},
	booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Bowman, Samuel R. and Angeli, Gabor and Potts, Christopher and Manning, Christopher D.},
	year = {2015},
	pages = {632--642},
	file = {Bowman et al. - 2015 - A large annotated corpus for learning natural lang.pdf:/Users/tiffanychien/Zotero/storage/MWKBYHA2/Bowman et al. - 2015 - A large annotated corpus for learning natural lang.pdf:application/pdf}
}

@inproceedings{ettinger_assessing_2018,
	address = {Santa Fe, New Mexico, USA},
	title = {Assessing {Composition} in {Sentence} {Vector} {Representations}},
	url = {https://www.aclweb.org/anthology/C18-1152},
	abstract = {An important component of achieving language understanding is mastering the composition of sentence meaning, but an immediate challenge to solving this problem is the opacity of sentence vector representations produced by current neural sentence composition models. We present a method to address this challenge, developing tasks that directly target compositional meaning information in sentence vector representations with a high degree of precision and control. To enable the creation of these controlled tasks, we introduce a specialized sentence generation system that produces large, annotated sentence sets meeting specified syntactic, semantic and lexical constraints. We describe the details of the method and generation system, and then present results of experiments applying our method to probe for compositional information in embeddings from a number of existing sentence composition models. We find that the method is able to extract useful information about the differing capacities of these models, and we discuss the implications of our results with respect to these systems' capturing of sentence information. We make available for public use the datasets used for these experiments, as well as the generation system.},
	urldate = {2019-06-11},
	booktitle = {Proceedings of the 27th {International} {Conference} on {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Ettinger, Allyson and Elgohary, Ahmed and Phillips, Colin and Resnik, Philip},
	month = aug,
	year = {2018},
	pages = {1790--1801},
	file = {Full Text PDF:/Users/tiffanychien/Zotero/storage/AJUTTPDR/Ettinger et al. - 2018 - Assessing Composition in Sentence Vector Represent.pdf:application/pdf}
}

@article{radford_language_nodate,
	title = {Language {Models} are {Unsupervised} {Multitask} {Learners}},
	abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspeciﬁc datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underﬁts WebText. Samples from the model reﬂect these improvements and contain coherent paragraphs of text. These ﬁndings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
	language = {en},
	author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
	pages = {24},
	file = {Radford et al. - Language Models are Unsupervised Multitask Learner.pdf:/Users/tiffanychien/Zotero/storage/DQW3UT7T/Radford et al. - Language Models are Unsupervised Multitask Learner.pdf:application/pdf}
}

@inproceedings{zanzotto_can_2017,
	title = {Can we explain natural language inference decisions taken with neural networks? {Inference} rules in distributed representations},
	shorttitle = {Can we explain natural language inference decisions taken with neural networks?},
	doi = {10.1109/IJCNN.2017.7966319},
	abstract = {Natural Language Inference (NLI) is a key, complex task where machine learning (ML) is playing an important role. However, ML has progressively obfuscated the role of linguistically-motivated inference rules, which should be the core of NLI systems. In this paper, we introduce distributed inference rules as a novel way to encode linguistically-motivated inference rules in learning interpretable NLI classifiers. We propose two encoders: the Distributed Partial Tree Encoder and the Distributed Smoothed Partial Tree Encoder. These encoders allow modeling syntactic and syntactic-semantic inference rules as distributed representations ready to be used in ML models over large datasets. Although far from the state-of-the-art of end-to-end deep learning systems on large datasets, our shallow networks positively exploit inference rules for NLI, improving over baseline systems. This is a first positive step towards interpretable and explainable end-to-end deep learning systems.},
	booktitle = {2017 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Zanzotto, F. M. and Ferrone, L.},
	month = may,
	year = {2017},
	keywords = {Bars, computational linguistics, deep learning systems, distributed inference rules, distributed representations, distributed smoothed partial-tree encoder, Encoding, inference mechanisms, interpretable NLI classifier learning, Kernel, learning (artificial intelligence), linguistically-motivated inference rule encoding, machine learning, Machine learning, ML, natural language inference decisions, natural language processing, neural networks, NLI systems, pattern classification, Semantics, shallow networks, syntactic-semantic inference rules, Syntactics, Training, tree data structures},
	pages = {3680--3687},
	file = {IEEE Xplore Abstract Record:/Users/tiffanychien/Zotero/storage/CNBR4DFR/7966319.html:text/html;IEEE Xplore Full Text PDF:/Users/tiffanychien/Zotero/storage/X3F3YE6P/Zanzotto and Ferrone - 2017 - Can we explain natural language inference decision.pdf:application/pdf}
}

@inproceedings{hu_harnessing_2016,
	address = {Berlin, Germany},
	title = {Harnessing {Deep} {Neural} {Networks} with {Logic} {Rules}},
	url = {https://www.aclweb.org/anthology/P16-1228},
	doi = {10.18653/v1/P16-1228},
	urldate = {2019-06-11},
	booktitle = {Proceedings of the 54th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Hu, Zhiting and Ma, Xuezhe and Liu, Zhengzhong and Hovy, Eduard and Xing, Eric},
	month = aug,
	year = {2016},
	pages = {2410--2420},
	file = {Full Text PDF:/Users/tiffanychien/Zotero/storage/WVCLAHC4/Hu et al. - 2016 - Harnessing Deep Neural Networks with Logic Rules.pdf:application/pdf}
}

@article{kang_adventure:_2018,
	title = {{AdvEntuRe}: {Adversarial} {Training} for {Textual} {Entailment} with {Knowledge}-{Guided} {Examples}},
	shorttitle = {{AdvEntuRe}},
	url = {http://arxiv.org/abs/1805.04680},
	abstract = {We consider the problem of learning textual entailment models with limited supervision (5K-10K training examples), and present two complementary approaches for it. First, we propose knowledge-guided adversarial example generators for incorporating large lexical resources in entailment models via only a handful of rule templates. Second, to make the entailment model - a discriminator - more robust, we propose the first GAN-style approach for training it using a natural language example generator that iteratively adjusts based on the discriminator's performance. We demonstrate effectiveness using two entailment datasets, where the proposed methods increase accuracy by 4.7\% on SciTail and by 2.8\% on a 1\% training sub-sample of SNLI. Notably, even a single hand-written rule, negate, improves the accuracy on the negation examples in SNLI by 6.1\%.},
	urldate = {2019-06-12},
	journal = {arXiv:1805.04680 [cs]},
	author = {Kang, Dongyeop and Khot, Tushar and Sabharwal, Ashish and Hovy, Eduard},
	month = may,
	year = {2018},
	note = {arXiv: 1805.04680},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv\:1805.04680 PDF:/Users/tiffanychien/Zotero/storage/FLN5HKET/Kang et al. - 2018 - AdvEntuRe Adversarial Training for Textual Entail.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/2SRW8F47/1805.html:text/html}
}

@article{rocktaschel_reasoning_2015,
	title = {Reasoning about {Entailment} with {Neural} {Attention}},
	url = {http://arxiv.org/abs/1509.06664},
	abstract = {While most approaches to automatically recognizing entailment relations have used classifiers employing hand engineered features derived from complex natural language processing pipelines, in practice their performance has been only slightly better than bag-of-word pair classifiers using only lexical similarity. The only attempt so far to build an end-to-end differentiable neural network for entailment failed to outperform such a simple similarity classifier. In this paper, we propose a neural model that reads two sentences to determine entailment using long short-term memory units. We extend this model with a word-by-word neural attention mechanism that encourages reasoning over entailments of pairs of words and phrases. Furthermore, we present a qualitative analysis of attention weights produced by this model, demonstrating such reasoning capabilities. On a large entailment dataset this model outperforms the previous best neural model and a classifier with engineered features by a substantial margin. It is the first generic end-to-end differentiable system that achieves state-of-the-art accuracy on a textual entailment dataset.},
	urldate = {2019-06-12},
	journal = {arXiv:1509.06664 [cs]},
	author = {Rocktäschel, Tim and Grefenstette, Edward and Hermann, Karl Moritz and Kočiský, Tomáš and Blunsom, Phil},
	month = sep,
	year = {2015},
	note = {arXiv: 1509.06664},
	keywords = {68T50, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, I.2.6, I.2.7},
	file = {arXiv\:1509.06664 PDF:/Users/tiffanychien/Zotero/storage/JUYFMZPG/Rocktäschel et al. - 2015 - Reasoning about Entailment with Neural Attention.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/3PJW26G2/1509.html:text/html}
}

@article{nie_analyzing_2018,
	title = {Analyzing {Compositionality}-{Sensitivity} of {NLI} {Models}},
	url = {http://arxiv.org/abs/1811.07033},
	abstract = {Success in natural language inference (NLI) should require a model to understand both lexical and compositional semantics. However, through adversarial evaluation, we find that several state-of-the-art models with diverse architectures are over-relying on the former and fail to use the latter. Further, this compositionality unawareness is not reflected via standard evaluation on current datasets. We show that removing RNNs in existing models or shuffling input words during training does not induce large performance loss despite the explicit removal of compositional information. Therefore, we propose a compositionality-sensitivity testing setup that analyzes models on natural examples from existing datasets that cannot be solved via lexical features alone (i.e., on which a bag-of-words model gives a high probability to one wrong label), hence revealing the models' actual compositionality awareness. We show that this setup not only highlights the limited compositional ability of current NLI models, but also differentiates model performance based on design, e.g., separating shallow bag-of-words models from deeper, linguistically-grounded tree-based models. Our evaluation setup is an important analysis tool: complementing currently existing adversarial and linguistically driven diagnostic evaluations, and exposing opportunities for future work on evaluating models' compositional understanding.},
	urldate = {2019-06-12},
	journal = {arXiv:1811.07033 [cs]},
	author = {Nie, Yixin and Wang, Yicheng and Bansal, Mohit},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.07033},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {arXiv\:1811.07033 PDF:/Users/tiffanychien/Zotero/storage/VIPWN3DK/Nie et al. - 2018 - Analyzing Compositionality-Sensitivity of NLI Mode.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/FAWVUT4S/1811.html:text/html}
}

@article{gururangan_annotation_2018,
	title = {Annotation {Artifacts} in {Natural} {Language} {Inference} {Data}},
	url = {http://arxiv.org/abs/1803.02324},
	abstract = {Large-scale datasets for natural language inference are created by presenting crowd workers with a sentence (premise), and asking them to generate three new sentences (hypotheses) that it entails, contradicts, or is logically neutral with respect to. We show that, in a significant portion of such data, this protocol leaves clues that make it possible to identify the label by looking only at the hypothesis, without observing the premise. Specifically, we show that a simple text categorization model can correctly classify the hypothesis alone in about 67\% of SNLI (Bowman et. al, 2015) and 53\% of MultiNLI (Williams et. al, 2017). Our analysis reveals that specific linguistic phenomena such as negation and vagueness are highly correlated with certain inference classes. Our findings suggest that the success of natural language inference models to date has been overestimated, and that the task remains a hard open problem.},
	urldate = {2019-06-12},
	journal = {arXiv:1803.02324 [cs]},
	author = {Gururangan, Suchin and Swayamdipta, Swabha and Levy, Omer and Schwartz, Roy and Bowman, Samuel R. and Smith, Noah A.},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.02324},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {arXiv\:1803.02324 PDF:/Users/tiffanychien/Zotero/storage/6Z42JG3K/Gururangan et al. - 2018 - Annotation Artifacts in Natural Language Inference.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/CJVGRHAJ/1803.html:text/html}
}

@article{salvatore_using_2019,
	title = {Using syntactical and logical forms to evaluate textual inference competence},
	url = {http://arxiv.org/abs/1905.05704},
	abstract = {Ongoing research on natural language inference where we propose a new set of tasks that require specific capacities over linguistic logical forms such as i) Boolean coordination, ii) quantifiers, iii) definitive description, and iv) counting operators.},
	urldate = {2019-06-12},
	journal = {arXiv:1905.05704 [cs]},
	author = {Salvatore, Felipe and Finger, Marcelo and Hirata Jr, Roberto},
	month = may,
	year = {2019},
	note = {arXiv: 1905.05704},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/IJA8KVZL/1905.html:text/html}
}

@article{evans_can_2018,
	title = {Can {Neural} {Networks} {Understand} {Logical} {Entailment}?},
	url = {http://arxiv.org/abs/1802.08535},
	abstract = {We introduce a new dataset of logical entailments for the purpose of measuring models' ability to capture and exploit the structure of logical expressions against an entailment prediction task. We use this task to compare a series of architectures which are ubiquitous in the sequence-processing literature, in addition to a new model class---PossibleWorldNets---which computes entailment as a "convolution over possible worlds". Results show that convolutional networks present the wrong inductive bias for this class of problems relative to LSTM RNNs, tree-structured neural networks outperform LSTM RNNs due to their enhanced ability to exploit the syntax of logic, and PossibleWorldNets outperform all benchmarks.},
	urldate = {2019-06-12},
	journal = {arXiv:1802.08535 [cs]},
	author = {Evans, Richard and Saxton, David and Amos, David and Kohli, Pushmeet and Grefenstette, Edward},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.08535},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv\:1802.08535 PDF:/Users/tiffanychien/Zotero/storage/DAJY93W9/Evans et al. - 2018 - Can Neural Networks Understand Logical Entailment.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/PFNXPGWX/1802.html:text/html}
}

@article{liu_multi-task_2019,
	title = {Multi-{Task} {Deep} {Neural} {Networks} for {Natural} {Language} {Understanding}},
	url = {http://arxiv.org/abs/1901.11504},
	abstract = {In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations in order to adapt to new tasks and domains. MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT (Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7\% (2.2\% absolute improvement). We also demonstrate using the SNLI and SciTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. The code and pre-trained models are publicly available at https://github.com/namisan/mt-dnn.},
	urldate = {2019-06-12},
	journal = {arXiv:1901.11504 [cs]},
	author = {Liu, Xiaodong and He, Pengcheng and Chen, Weizhu and Gao, Jianfeng},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.11504},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1901.11504 PDF:/Users/tiffanychien/Zotero/storage/WUJQ2XK8/Liu et al. - 2019 - Multi-Task Deep Neural Networks for Natural Langua.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/CEYXI62C/1901.html:text/html}
}

@article{hinton_distilling_2015,
	title = {Distilling the {Knowledge} in a {Neural} {Network}},
	url = {http://arxiv.org/abs/1503.02531},
	abstract = {A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.},
	urldate = {2019-06-13},
	journal = {arXiv:1503.02531 [cs, stat]},
	author = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
	month = mar,
	year = {2015},
	note = {arXiv: 1503.02531},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	file = {arXiv\:1503.02531 PDF:/Users/tiffanychien/Zotero/storage/2KNPMXWB/Hinton et al. - 2015 - Distilling the Knowledge in a Neural Network.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/7AXDCHPS/1503.html:text/html}
}

@article{wang_glue:_2018,
	title = {{GLUE}: {A} {Multi}-{Task} {Benchmark} and {Analysis} {Platform} for {Natural} {Language} {Understanding}},
	shorttitle = {{GLUE}},
	url = {http://arxiv.org/abs/1804.07461},
	abstract = {For natural language understanding (NLU) technology to be maximally useful, both practically and as a scientific object of study, it must be general: it must be able to process language in a way that is not exclusively tailored to any one specific task or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation benchmark (GLUE), a tool for evaluating and analyzing the performance of models across a diverse range of existing NLU tasks. GLUE is model-agnostic, but it incentivizes sharing knowledge across tasks because certain tasks have very limited training data. We further provide a hand-crafted diagnostic test suite that enables detailed linguistic analysis of NLU models. We evaluate baselines based on current methods for multi-task and transfer learning and find that they do not immediately give substantial improvements over the aggregate performance of training a separate model per task, indicating room for improvement in developing general and robust NLU systems.},
	urldate = {2019-06-14},
	journal = {arXiv:1804.07461 [cs]},
	author = {Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.07461},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1804.07461 PDF:/Users/tiffanychien/Zotero/storage/KVZA5YHF/Wang et al. - 2018 - GLUE A Multi-Task Benchmark and Analysis Platform.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/YGKRYXFA/1804.html:text/html}
}

@article{chen_enhancing_2016,
	title = {Enhancing and {Combining} {Sequential} and {Tree} {LSTM} for {Natural} {Language} {Inference}},
	volume = {abs/1609.06038},
	abstract = {Reasoning and inference are central to human and artificial intelligence. Modeling inference in human language is notoriously challenging but is fundamental to natural language understanding and many applications. With the availability of large annotated data, neural network models have recently advanced the field significantly. In this paper, we present a new state-of-the-art result, achieving the accuracy of 88.3\% on the standard benchmark, the Stanford Natural Language Inference dataset. This result is achieved first through our enhanced sequential encoding model, which outperforms the previous best model that employs more complicated network architectures, suggesting that the potential of sequential LSTM-based models have not been fully explored yet in previous work. We further show that by explicitly considering recursive architectures, we achieve additional improvement. Particularly, incorporating syntactic parse information contributes to our best result; it improves the performance even when the parse information is added to an already very strong system.},
	journal = {CoRR},
	author = {Chen, Qian and Zhu, Xiao-Dan and Ling, Zhen-Hua and Wei, Si and Jiang, Hui},
	year = {2016},
	keywords = {Artificial intelligence, B-tree, Benchmark (computing), Long short-term memory, Native-language identification, Natural language, Natural language understanding, Network search engine, Parsing, Recursion},
	file = {Full Text PDF:/Users/tiffanychien/Zotero/storage/HMHUTEXK/Chen et al. - 2016 - Enhancing and Combining Sequential and Tree LSTM f.pdf:application/pdf}
}

@article{chen_enhanced_2016,
	title = {Enhanced {LSTM} for {Natural} {Language} {Inference}},
	url = {http://arxiv.org/abs/1609.06038},
	abstract = {Reasoning and inference are central to human and artificial intelligence. Modeling inference in human language is very challenging. With the availability of large annotated data (Bowman et al., 2015), it has recently become feasible to train neural network based inference models, which have shown to be very effective. In this paper, we present a new state-of-the-art result, achieving the accuracy of 88.6\% on the Stanford Natural Language Inference Dataset. Unlike the previous top models that use very complicated network architectures, we first demonstrate that carefully designing sequential inference models based on chain LSTMs can outperform all previous models. Based on this, we further show that by explicitly considering recursive architectures in both local inference modeling and inference composition, we achieve additional improvement. Particularly, incorporating syntactic parsing information contributes to our best result---it further improves the performance even when added to the already very strong model.},
	urldate = {2019-06-14},
	journal = {arXiv:1609.06038 [cs]},
	author = {Chen, Qian and Zhu, Xiaodan and Ling, Zhenhua and Wei, Si and Jiang, Hui and Inkpen, Diana},
	month = sep,
	year = {2016},
	note = {arXiv: 1609.06038},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1609.06038 PDF:/Users/tiffanychien/Zotero/storage/EUYSSQFR/Chen et al. - 2016 - Enhanced LSTM for Natural Language Inference.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/DT7S49IV/1609.html:text/html}
}

@inproceedings{chen_neural_2018,
	address = {Melbourne, Australia},
	title = {Neural {Natural} {Language} {Inference} {Models} {Enhanced} with {External} {Knowledge}},
	url = {https://www.aclweb.org/anthology/P18-1224},
	abstract = {Modeling natural language inference is a very challenging task. With the availability of large annotated data, it has recently become feasible to train complex models such as neural-network-based inference models, which have shown to achieve the state-of-the-art performance. Although there exist relatively large annotated data, can machines learn all knowledge needed to perform natural language inference (NLI) from these data? If not, how can neural-network-based NLI models benefit from external knowledge and how to build NLI models to leverage it? In this paper, we enrich the state-of-the-art neural natural language inference models with external knowledge. We demonstrate that the proposed models improve neural NLI models to achieve the state-of-the-art performance on the SNLI and MultiNLI datasets.},
	urldate = {2019-06-14},
	booktitle = {Proceedings of the 56th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Chen, Qian and Zhu, Xiaodan and Ling, Zhen-Hua and Inkpen, Diana and Wei, Si},
	month = jul,
	year = {2018},
	pages = {2406--2417},
	file = {Full Text PDF:/Users/tiffanychien/Zotero/storage/YVTP8YWY/Chen et al. - 2018 - Neural Natural Language Inference Models Enhanced .pdf:application/pdf}
}

@article{yang_assessing_2019,
	title = {Assessing the {Ability} of {Self}-{Attention} {Networks} to {Learn} {Word} {Order}},
	url = {http://arxiv.org/abs/1906.00592},
	abstract = {Self-attention networks (SAN) have attracted a lot of interests due to their high parallelization and strong performance on a variety of NLP tasks, e.g. machine translation. Due to the lack of recurrence structure such as recurrent neural networks (RNN), SAN is ascribed to be weak at learning positional information of words for sequence modeling. However, neither this speculation has been empirically confirmed, nor explanations for their strong performances on machine translation tasks when "lacking positional information" have been explored. To this end, we propose a novel word reordering detection task to quantify how well the word order information learned by SAN and RNN. Specifically, we randomly move one word to another position, and examine whether a trained model can detect both the original and inserted positions. Experimental results reveal that: 1) SAN trained on word reordering detection indeed has difficulty learning the positional information even with the position embedding; and 2) SAN trained on machine translation learns better positional information than its RNN counterpart, in which position embedding plays a critical role. Although recurrence structure make the model more universally-effective on learning word order, learning objectives matter more in the downstream tasks such as machine translation.},
	urldate = {2019-06-14},
	journal = {arXiv:1906.00592 [cs]},
	author = {Yang, Baosong and Wang, Longyue and Wong, Derek F. and Chao, Lidia S. and Tu, Zhaopeng},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.00592},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {arXiv\:1906.00592 PDF:/Users/tiffanychien/Zotero/storage/8ECC6DCJ/Yang et al. - 2019 - Assessing the Ability of Self-Attention Networks t.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/3BQR8QNN/1906.html:text/html}
}

@article{chronopoulou_embarrassingly_2019,
	title = {An {Embarrassingly} {Simple} {Approach} for {Transfer} {Learning} from {Pretrained} {Language} {Models}},
	url = {http://arxiv.org/abs/1902.10547},
	abstract = {A growing number of state-of-the-art transfer learning methods employ language models pretrained on large generic corpora. In this paper we present a conceptually simple and effective transfer learning approach that addresses the problem of catastrophic forgetting. Specifically, we combine the task-specific optimization function with an auxiliary language model objective, which is adjusted during the training process. This preserves language regularities captured by language models, while enabling sufficient adaptation for solving the target task. Our method does not require pretraining or finetuning separate components of the network and we train our models end-to-end in a single step. We present results on a variety of challenging affective and text classification tasks, surpassing well established transfer learning methods with greater level of complexity.},
	urldate = {2019-06-14},
	journal = {arXiv:1902.10547 [cs]},
	author = {Chronopoulou, Alexandra and Baziotis, Christos and Potamianos, Alexandros},
	month = feb,
	year = {2019},
	note = {arXiv: 1902.10547},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv\:1902.10547 PDF:/Users/tiffanychien/Zotero/storage/3TYDT3GZ/Chronopoulou et al. - 2019 - An Embarrassingly Simple Approach for Transfer Lea.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/CEPSBZSU/1902.html:text/html}
}

@article{liu_improving_2019-1,
	title = {Improving {Multi}-{Task} {Deep} {Neural} {Networks} via {Knowledge} {Distillation} for {Natural} {Language} {Understanding}},
	url = {http://arxiv.org/abs/1904.09482},
	abstract = {This paper explores the use of knowledge distillation to improve a Multi-Task Deep Neural Network (MT-DNN) (Liu et al., 2019) for learning text representations across multiple natural language understanding tasks. Although ensemble learning can improve model performance, serving an ensemble of large DNNs such as MT-DNN can be prohibitively expensive. Here we apply the knowledge distillation method (Hinton et al., 2015) in the multi-task learning setting. For each task, we train an ensemble of different MT-DNNs (teacher) that outperforms any single model, and then train a single MT-DNN (student) via multi-task learning to {\textbackslash}emph\{distill\} knowledge from these ensemble teachers. We show that the distilled MT-DNN significantly outperforms the original MT-DNN on 7 out of 9 GLUE tasks, pushing the GLUE benchmark (single model) to 83.7{\textbackslash}\% (1.5{\textbackslash}\% absolute improvement{\textbackslash}footnote\{ Based on the GLUE leaderboard at https://gluebenchmark.com/leaderboard as of April 1, 2019.\}). The code and pre-trained models will be made publicly available at https://github.com/namisan/mt-dnn.},
	urldate = {2019-06-14},
	journal = {arXiv:1904.09482 [cs]},
	author = {Liu, Xiaodong and He, Pengcheng and Chen, Weizhu and Gao, Jianfeng},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.09482},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1904.09482 PDF:/Users/tiffanychien/Zotero/storage/224ZN3BL/Liu et al. - 2019 - Improving Multi-Task Deep Neural Networks via Know.pdf:application/pdf;arXiv.org Snapshot:/Users/tiffanychien/Zotero/storage/KAGBG7VN/1904.html:text/html}
}